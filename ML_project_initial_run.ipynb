{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML_project_initial_run.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "2vWpT6NBgmhO"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RzjYtioc0BL_",
        "outputId": "b17d9969-d03f-4752-e5d2-e979af514a11"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense"
      ],
      "metadata": {
        "id": "vdrDE0Uf0vNi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import KFold"
      ],
      "metadata": {
        "id": "Wq9v7t6B4X-I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regular_feature_path = \"/content/drive/MyDrive/ML_project_dataset/Normalized_Features_1/\"\n",
        "new_feature_path = \"/content/drive/MyDrive/ML_project_dataset/Final_Normalized_Features/\""
      ],
      "metadata": {
        "id": "6300AcQwhDHF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "country_name_list = ['Belgium_features.csv','England_features.csv','France_features.csv',\n",
        "                     'Germany_features.csv','Greece_features.csv','Italy_features.csv',\n",
        "                     'Netherlands_features.csv','Portugal_features.csv',\n",
        "                     'Scotland_features.csv','Spain_features.csv']\n",
        "countries_regular = ['Belgium', 'England','France', 'Germany', 'Greece', 'Italy', 'Netherlands', 'Portugal',\n",
        "                     'Scotland', 'Spain']"
      ],
      "metadata": {
        "id": "92YYJzEyhg3x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Regular data Neural Net"
      ],
      "metadata": {
        "id": "NYSCOEtSMG0L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_df = pd.read_csv(\"/content/drive/MyDrive/ML_project_dataset/transfers_data.csv\")"
      ],
      "metadata": {
        "id": "fkp5auNJ2Uub"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transfer_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GgSTf9ta2ei2",
        "outputId": "ed9cd2a8-0b4e-4860-a0ca-b6971e286d0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'Name', 'Position', 'Age', 'Team_from', 'League_from',\n",
              "       'Team_to', 'League_to', 'Season', 'Transfer_fee', 'Country Column',\n",
              "       'Nationality'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "list for the country csv names"
      ],
      "metadata": {
        "id": "zzZwn6y_hhv5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_feature_df = pd.read_csv(regular_feature_path + \"England_features.csv\")"
      ],
      "metadata": {
        "id": "opnegibc21Z9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#converting output column to integer type for classification\n",
        "eng_feature_df[\"win\"] = eng_feature_df[\"win\"].astype('int')"
      ],
      "metadata": {
        "id": "m83nLT_43h--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_feature_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "3u4ZtwW726WA",
        "outputId": "3eeb9373-aca9-4f7c-a6da-18acab3c6251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  team_rank  rank_diff  win_rate  Team_Venue_Form  \\\n",
              "0           0        1.0   0.009217       0.0         0.583333   \n",
              "1           1        1.0   0.000000       0.2         0.416667   \n",
              "2           2        1.0   0.152074       0.0         0.416667   \n",
              "3           3        1.0   0.543779       0.0         0.500000   \n",
              "4           4        1.0   0.023041       0.5         0.250000   \n",
              "\n",
              "   Opp_Venue_Form  Team_Cumul_GD  Opp_Cumul_GD  win  \n",
              "0        0.466667       0.611111      0.604167    0  \n",
              "1        0.600000       0.277778      0.791667    0  \n",
              "2        0.533333       0.277778      0.583333    1  \n",
              "3        0.266667       0.333333      0.520833    1  \n",
              "4        0.533333       0.277778      0.666667    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d96db42d-30a3-4a25-928e-b8a78147c207\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>team_rank</th>\n",
              "      <th>rank_diff</th>\n",
              "      <th>win_rate</th>\n",
              "      <th>Team_Venue_Form</th>\n",
              "      <th>Opp_Venue_Form</th>\n",
              "      <th>Team_Cumul_GD</th>\n",
              "      <th>Opp_Cumul_GD</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.009217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.152074</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.543779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.023041</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d96db42d-30a3-4a25-928e-b8a78147c207')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d96db42d-30a3-4a25-928e-b8a78147c207 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d96db42d-30a3-4a25-928e-b8a78147c207');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X = eng_feature_df[['team_rank', 'rank_diff', 'win_rate', 'Team_Venue_Form', 'Opp_Venue_Form', 'Team_Cumul_GD', 'Opp_Cumul_GD']]\n",
        "y = eng_feature_df['win']"
      ],
      "metadata": {
        "id": "4SquTG7G33Q8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)"
      ],
      "metadata": {
        "id": "ZPfIsENX4oEN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQUQNDib5njO",
        "outputId": "6dd1c269-31a3-4756-fb49-fb80fe76345c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=X.shape[1], activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "loss_fn = keras.losses.BinaryCrossentropy()\n",
        "model.compile(loss=loss_fn, optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hnen4MN-2Ry5",
        "outputId": "c0439b71-a501-4437-b044-8f2ebf8ecb2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(X_train, y_train, epochs=100, batch_size=5, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpvHmY7W72Qr",
        "outputId": "eef72b6b-f397-471e-a916-4aecf0b87073"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "29/29 [==============================] - 1s 11ms/step - loss: 0.7537 - accuracy: 0.3958 - val_loss: 0.7058 - val_accuracy: 0.4595\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.7257 - accuracy: 0.3819 - val_loss: 0.6980 - val_accuracy: 0.5135\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.7126 - accuracy: 0.3542 - val_loss: 0.6940 - val_accuracy: 0.5946\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.7032 - accuracy: 0.3681 - val_loss: 0.6935 - val_accuracy: 0.5135\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6961 - accuracy: 0.4097 - val_loss: 0.6928 - val_accuracy: 0.3784\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.5417 - val_loss: 0.6928 - val_accuracy: 0.5405\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.6250 - val_loss: 0.6924 - val_accuracy: 0.5135\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6826 - accuracy: 0.6458 - val_loss: 0.6930 - val_accuracy: 0.5676\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6784 - accuracy: 0.6875 - val_loss: 0.6930 - val_accuracy: 0.5135\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6734 - accuracy: 0.6944 - val_loss: 0.6900 - val_accuracy: 0.5135\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6687 - accuracy: 0.7222 - val_loss: 0.6885 - val_accuracy: 0.5405\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7014 - val_loss: 0.6870 - val_accuracy: 0.5405\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6583 - accuracy: 0.7361 - val_loss: 0.6825 - val_accuracy: 0.5676\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.7014 - val_loss: 0.6856 - val_accuracy: 0.5405\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6467 - accuracy: 0.6806 - val_loss: 0.6927 - val_accuracy: 0.4595\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6377 - accuracy: 0.6875 - val_loss: 0.6937 - val_accuracy: 0.4595\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6310 - accuracy: 0.6806 - val_loss: 0.6950 - val_accuracy: 0.4595\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.6275 - accuracy: 0.6806 - val_loss: 0.6962 - val_accuracy: 0.4595\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6196 - accuracy: 0.6944 - val_loss: 0.6944 - val_accuracy: 0.4595\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6135 - accuracy: 0.6944 - val_loss: 0.6950 - val_accuracy: 0.4595\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6074 - accuracy: 0.6875 - val_loss: 0.6937 - val_accuracy: 0.4595\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6031 - accuracy: 0.7222 - val_loss: 0.6929 - val_accuracy: 0.4865\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5966 - accuracy: 0.7153 - val_loss: 0.6906 - val_accuracy: 0.5135\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5916 - accuracy: 0.7083 - val_loss: 0.6873 - val_accuracy: 0.5135\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5859 - accuracy: 0.7153 - val_loss: 0.6860 - val_accuracy: 0.5135\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7083 - val_loss: 0.6870 - val_accuracy: 0.5135\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5781 - accuracy: 0.7083 - val_loss: 0.6817 - val_accuracy: 0.5405\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5731 - accuracy: 0.7153 - val_loss: 0.6853 - val_accuracy: 0.5135\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5700 - accuracy: 0.7083 - val_loss: 0.6822 - val_accuracy: 0.5135\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5678 - accuracy: 0.7014 - val_loss: 0.6826 - val_accuracy: 0.5405\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5655 - accuracy: 0.7083 - val_loss: 0.6805 - val_accuracy: 0.5676\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5621 - accuracy: 0.7083 - val_loss: 0.6777 - val_accuracy: 0.5405\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5586 - accuracy: 0.6944 - val_loss: 0.6803 - val_accuracy: 0.5405\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5578 - accuracy: 0.7153 - val_loss: 0.6788 - val_accuracy: 0.5405\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5547 - accuracy: 0.7153 - val_loss: 0.6757 - val_accuracy: 0.5405\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5551 - accuracy: 0.7083 - val_loss: 0.6769 - val_accuracy: 0.5405\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5512 - accuracy: 0.7222 - val_loss: 0.6729 - val_accuracy: 0.5405\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5503 - accuracy: 0.6944 - val_loss: 0.6724 - val_accuracy: 0.5405\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5498 - accuracy: 0.7014 - val_loss: 0.6706 - val_accuracy: 0.5405\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5482 - accuracy: 0.7014 - val_loss: 0.6708 - val_accuracy: 0.5135\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5448 - accuracy: 0.7222 - val_loss: 0.6691 - val_accuracy: 0.5405\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5455 - accuracy: 0.7083 - val_loss: 0.6687 - val_accuracy: 0.5676\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5437 - accuracy: 0.7222 - val_loss: 0.6652 - val_accuracy: 0.5676\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5405 - accuracy: 0.7153 - val_loss: 0.6655 - val_accuracy: 0.5405\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5400 - accuracy: 0.7083 - val_loss: 0.6650 - val_accuracy: 0.5676\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.7292 - val_loss: 0.6635 - val_accuracy: 0.5676\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5351 - accuracy: 0.7222 - val_loss: 0.6655 - val_accuracy: 0.5405\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5342 - accuracy: 0.7292 - val_loss: 0.6602 - val_accuracy: 0.5676\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5334 - accuracy: 0.7361 - val_loss: 0.6569 - val_accuracy: 0.5676\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5314 - accuracy: 0.7292 - val_loss: 0.6567 - val_accuracy: 0.5676\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5320 - accuracy: 0.7361 - val_loss: 0.6570 - val_accuracy: 0.5676\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5330 - accuracy: 0.7292 - val_loss: 0.6573 - val_accuracy: 0.5676\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5303 - accuracy: 0.7292 - val_loss: 0.6539 - val_accuracy: 0.5676\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5310 - accuracy: 0.7500 - val_loss: 0.6509 - val_accuracy: 0.5676\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5316 - accuracy: 0.7500 - val_loss: 0.6526 - val_accuracy: 0.5676\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.5257 - accuracy: 0.7361 - val_loss: 0.6510 - val_accuracy: 0.5676\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5268 - accuracy: 0.7361 - val_loss: 0.6501 - val_accuracy: 0.5676\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.5260 - accuracy: 0.7431 - val_loss: 0.6483 - val_accuracy: 0.5676\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5269 - accuracy: 0.7361 - val_loss: 0.6460 - val_accuracy: 0.5676\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5244 - accuracy: 0.7431 - val_loss: 0.6445 - val_accuracy: 0.5676\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.7431 - val_loss: 0.6445 - val_accuracy: 0.5946\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5232 - accuracy: 0.7431 - val_loss: 0.6438 - val_accuracy: 0.5676\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5214 - accuracy: 0.7361 - val_loss: 0.6424 - val_accuracy: 0.5676\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.5212 - accuracy: 0.7361 - val_loss: 0.6423 - val_accuracy: 0.5676\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5194 - accuracy: 0.7361 - val_loss: 0.6408 - val_accuracy: 0.5676\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5208 - accuracy: 0.7431 - val_loss: 0.6416 - val_accuracy: 0.5676\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5181 - accuracy: 0.7361 - val_loss: 0.6401 - val_accuracy: 0.5676\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5189 - accuracy: 0.7500 - val_loss: 0.6367 - val_accuracy: 0.6216\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5150 - accuracy: 0.7500 - val_loss: 0.6389 - val_accuracy: 0.5676\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5166 - accuracy: 0.7500 - val_loss: 0.6378 - val_accuracy: 0.5676\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5154 - accuracy: 0.7361 - val_loss: 0.6340 - val_accuracy: 0.5946\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5167 - accuracy: 0.7431 - val_loss: 0.6344 - val_accuracy: 0.6216\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5140 - accuracy: 0.7431 - val_loss: 0.6343 - val_accuracy: 0.5946\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5150 - accuracy: 0.7431 - val_loss: 0.6321 - val_accuracy: 0.6216\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5180 - accuracy: 0.7569 - val_loss: 0.6337 - val_accuracy: 0.5676\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5174 - accuracy: 0.7500 - val_loss: 0.6308 - val_accuracy: 0.6216\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5146 - accuracy: 0.7431 - val_loss: 0.6325 - val_accuracy: 0.5676\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5104 - accuracy: 0.7500 - val_loss: 0.6310 - val_accuracy: 0.6216\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5128 - accuracy: 0.7569 - val_loss: 0.6289 - val_accuracy: 0.5946\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5097 - accuracy: 0.7500 - val_loss: 0.6290 - val_accuracy: 0.6216\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5108 - accuracy: 0.7431 - val_loss: 0.6292 - val_accuracy: 0.6216\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5090 - accuracy: 0.7431 - val_loss: 0.6278 - val_accuracy: 0.6216\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5098 - accuracy: 0.7361 - val_loss: 0.6268 - val_accuracy: 0.5946\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5081 - accuracy: 0.7500 - val_loss: 0.6268 - val_accuracy: 0.6216\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 10ms/step - loss: 0.5102 - accuracy: 0.7569 - val_loss: 0.6267 - val_accuracy: 0.6216\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 5ms/step - loss: 0.5093 - accuracy: 0.7292 - val_loss: 0.6257 - val_accuracy: 0.6216\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5075 - accuracy: 0.7500 - val_loss: 0.6258 - val_accuracy: 0.5946\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5093 - accuracy: 0.7569 - val_loss: 0.6245 - val_accuracy: 0.6216\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 6ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.6255 - val_accuracy: 0.6216\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.5050 - accuracy: 0.7500 - val_loss: 0.6249 - val_accuracy: 0.6216\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 9ms/step - loss: 0.5047 - accuracy: 0.7500 - val_loss: 0.6239 - val_accuracy: 0.6216\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.5070 - accuracy: 0.7500 - val_loss: 0.6234 - val_accuracy: 0.6486\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 13ms/step - loss: 0.5066 - accuracy: 0.7431 - val_loss: 0.6231 - val_accuracy: 0.6757\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.6224 - val_accuracy: 0.6216\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.5033 - accuracy: 0.7500 - val_loss: 0.6224 - val_accuracy: 0.6486\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.5045 - accuracy: 0.7431 - val_loss: 0.6225 - val_accuracy: 0.6216\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 8ms/step - loss: 0.5023 - accuracy: 0.7639 - val_loss: 0.6206 - val_accuracy: 0.6486\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.5039 - accuracy: 0.7569 - val_loss: 0.6210 - val_accuracy: 0.6216\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 11ms/step - loss: 0.5068 - accuracy: 0.7639 - val_loss: 0.6223 - val_accuracy: 0.6757\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 7ms/step - loss: 0.5107 - accuracy: 0.7361 - val_loss: 0.6211 - val_accuracy: 0.6486\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max(history.history['val_accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgQCg8q3vYTa",
        "outputId": "fb406bef-c43f-4104-bab7-16ebcd9f6435"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7567567825317383"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the model after training\n",
        "test_results = model.evaluate(X_test, y_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3yTwc3HF89zH",
        "outputId": "b9a83f65-69ad-4045-f0b4-93cc03f5c4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5478 - accuracy: 0.7174\n",
            "Test results - Loss: 0.547821044921875 - Accuracy: 71.7391312122345%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Here are the new transfer features:"
      ],
      "metadata": {
        "id": "2vWpT6NBgmhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eng_new_feature_df = pd.read_csv(new_feature_path + \"England_features.csv\")\n",
        "eng_new_feature_df['win'] = eng_new_feature_df['win'].astype('int')"
      ],
      "metadata": {
        "id": "tuiOImuqgusY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "eng_new_feature_df.head(5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "6Q2mYLMFihq1",
        "outputId": "7b5f34d1-9cde-479f-d2d8-ec8e17f7a7a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0  team_rank  rank_diff  win_rate  Team_Venue_Form  \\\n",
              "0           0        1.0   0.009217       0.0         0.583333   \n",
              "1           1        1.0   0.000000       0.2         0.416667   \n",
              "2           2        1.0   0.152074       0.0         0.416667   \n",
              "3           3        1.0   0.543779       0.0         0.500000   \n",
              "4           4        1.0   0.023041       0.5         0.250000   \n",
              "\n",
              "   Opp_Venue_Form  Team_Cumul_GD  Opp_Cumul_GD  Total_exp  Total_Exp_local  \\\n",
              "0        0.466667       0.611111      0.604167   0.156965         0.360352   \n",
              "1        0.600000       0.277778      0.791667   0.156965         0.360352   \n",
              "2        0.533333       0.277778      0.583333   0.156965         0.360352   \n",
              "3        0.266667       0.333333      0.520833   0.156965         0.360352   \n",
              "4        0.533333       0.277778      0.666667   0.156965         0.360352   \n",
              "\n",
              "   Total_Exp_youth  win  \n",
              "0         0.237738    0  \n",
              "1         0.237738    0  \n",
              "2         0.237738    1  \n",
              "3         0.237738    1  \n",
              "4         0.237738    0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-b46a2b4c-b1e2-4fa9-b63e-984308382b13\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>team_rank</th>\n",
              "      <th>rank_diff</th>\n",
              "      <th>win_rate</th>\n",
              "      <th>Team_Venue_Form</th>\n",
              "      <th>Opp_Venue_Form</th>\n",
              "      <th>Team_Cumul_GD</th>\n",
              "      <th>Opp_Cumul_GD</th>\n",
              "      <th>Total_exp</th>\n",
              "      <th>Total_Exp_local</th>\n",
              "      <th>Total_Exp_youth</th>\n",
              "      <th>win</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.009217</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.466667</td>\n",
              "      <td>0.611111</td>\n",
              "      <td>0.604167</td>\n",
              "      <td>0.156965</td>\n",
              "      <td>0.360352</td>\n",
              "      <td>0.237738</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.2</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.600000</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.791667</td>\n",
              "      <td>0.156965</td>\n",
              "      <td>0.360352</td>\n",
              "      <td>0.237738</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.152074</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.416667</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.583333</td>\n",
              "      <td>0.156965</td>\n",
              "      <td>0.360352</td>\n",
              "      <td>0.237738</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.543779</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.520833</td>\n",
              "      <td>0.156965</td>\n",
              "      <td>0.360352</td>\n",
              "      <td>0.237738</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.023041</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0.250000</td>\n",
              "      <td>0.533333</td>\n",
              "      <td>0.277778</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.156965</td>\n",
              "      <td>0.360352</td>\n",
              "      <td>0.237738</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-b46a2b4c-b1e2-4fa9-b63e-984308382b13')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-b46a2b4c-b1e2-4fa9-b63e-984308382b13 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-b46a2b4c-b1e2-4fa9-b63e-984308382b13');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eng_new_feature_df.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fvydsNgViq6q",
        "outputId": "9460dd8a-3be1-41d9-c11f-b4137a98cb96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Unnamed: 0', 'team_rank', 'rank_diff', 'win_rate', 'Team_Venue_Form',\n",
              "       'Opp_Venue_Form', 'Team_Cumul_GD', 'Opp_Cumul_GD', 'Total_exp',\n",
              "       'Total_Exp_local', 'Total_Exp_youth', 'win'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_new = eng_new_feature_df[eng_new_feature_df.columns[1:-1]]\n",
        "y_new = eng_new_feature_df['win']"
      ],
      "metadata": {
        "id": "f4Ff3W-LjAPv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "Xn_train, Xn_test, yn_train, yn_test = train_test_split(X_new, y_new, test_size=0.2)"
      ],
      "metadata": {
        "id": "TUfBRW8GjX71"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_new.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uGMCNF9Fjo_p",
        "outputId": "35e13fae-9d03-457f-c7a3-ae9d3ab7a3a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(227, 10)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_new = Sequential()\n",
        "model_new.add(Dense(12, input_dim=X_new.shape[1], activation='relu'))\n",
        "model_new.add(Dense(8, activation='relu'))\n",
        "model_new.add(Dense(1, activation='sigmoid'))\n",
        "loss_fn = keras.losses.BinaryCrossentropy()\n",
        "model_new.compile(loss=loss_fn, optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9e8X_YYkjnKp",
        "outputId": "35b9c2e9-63b7-44e9-9d11-b9f43a9c5e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "history_new = model_new.fit(Xn_train, yn_train, epochs=200, batch_size=5, verbose=1, validation_split=0.2)"
      ],
      "metadata": {
        "id": "uYDT3qKcj4Ee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f361456-8835-4bf1-ba73-dfc9959d8a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "29/29 [==============================] - 1s 8ms/step - loss: 0.6788 - accuracy: 0.6181 - val_loss: 0.6435 - val_accuracy: 0.6216\n",
            "Epoch 2/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6585 - accuracy: 0.6458 - val_loss: 0.6324 - val_accuracy: 0.7838\n",
            "Epoch 3/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6452 - accuracy: 0.6458 - val_loss: 0.6251 - val_accuracy: 0.7568\n",
            "Epoch 4/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.6363 - accuracy: 0.6667 - val_loss: 0.6162 - val_accuracy: 0.7568\n",
            "Epoch 5/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6285 - accuracy: 0.6736 - val_loss: 0.6079 - val_accuracy: 0.7568\n",
            "Epoch 6/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6217 - accuracy: 0.6528 - val_loss: 0.6009 - val_accuracy: 0.7568\n",
            "Epoch 7/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6129 - accuracy: 0.6806 - val_loss: 0.5883 - val_accuracy: 0.7568\n",
            "Epoch 8/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6091 - accuracy: 0.6806 - val_loss: 0.5842 - val_accuracy: 0.7568\n",
            "Epoch 9/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6021 - accuracy: 0.6944 - val_loss: 0.5753 - val_accuracy: 0.7568\n",
            "Epoch 10/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5944 - accuracy: 0.6875 - val_loss: 0.5665 - val_accuracy: 0.7568\n",
            "Epoch 11/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5896 - accuracy: 0.7083 - val_loss: 0.5626 - val_accuracy: 0.7568\n",
            "Epoch 12/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5873 - accuracy: 0.6806 - val_loss: 0.5571 - val_accuracy: 0.7568\n",
            "Epoch 13/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5783 - accuracy: 0.6944 - val_loss: 0.5497 - val_accuracy: 0.7568\n",
            "Epoch 14/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5742 - accuracy: 0.6736 - val_loss: 0.5484 - val_accuracy: 0.7568\n",
            "Epoch 15/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5711 - accuracy: 0.7014 - val_loss: 0.5430 - val_accuracy: 0.7568\n",
            "Epoch 16/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5670 - accuracy: 0.6806 - val_loss: 0.5414 - val_accuracy: 0.7568\n",
            "Epoch 17/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5706 - accuracy: 0.6806 - val_loss: 0.5360 - val_accuracy: 0.7297\n",
            "Epoch 18/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5606 - accuracy: 0.6875 - val_loss: 0.5347 - val_accuracy: 0.7568\n",
            "Epoch 19/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5614 - accuracy: 0.6944 - val_loss: 0.5356 - val_accuracy: 0.7568\n",
            "Epoch 20/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5600 - accuracy: 0.7083 - val_loss: 0.5316 - val_accuracy: 0.7297\n",
            "Epoch 21/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5559 - accuracy: 0.6667 - val_loss: 0.5279 - val_accuracy: 0.7297\n",
            "Epoch 22/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5521 - accuracy: 0.6806 - val_loss: 0.5280 - val_accuracy: 0.7568\n",
            "Epoch 23/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5517 - accuracy: 0.7014 - val_loss: 0.5267 - val_accuracy: 0.7568\n",
            "Epoch 24/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5512 - accuracy: 0.6944 - val_loss: 0.5362 - val_accuracy: 0.7297\n",
            "Epoch 25/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5503 - accuracy: 0.7083 - val_loss: 0.5244 - val_accuracy: 0.7297\n",
            "Epoch 26/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5470 - accuracy: 0.6944 - val_loss: 0.5258 - val_accuracy: 0.7568\n",
            "Epoch 27/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5492 - accuracy: 0.6944 - val_loss: 0.5206 - val_accuracy: 0.7297\n",
            "Epoch 28/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5457 - accuracy: 0.6875 - val_loss: 0.5196 - val_accuracy: 0.7297\n",
            "Epoch 29/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5451 - accuracy: 0.7292 - val_loss: 0.5176 - val_accuracy: 0.7027\n",
            "Epoch 30/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5432 - accuracy: 0.6944 - val_loss: 0.5226 - val_accuracy: 0.7568\n",
            "Epoch 31/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5415 - accuracy: 0.6944 - val_loss: 0.5206 - val_accuracy: 0.7568\n",
            "Epoch 32/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5414 - accuracy: 0.7083 - val_loss: 0.5176 - val_accuracy: 0.7297\n",
            "Epoch 33/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5402 - accuracy: 0.6944 - val_loss: 0.5181 - val_accuracy: 0.7297\n",
            "Epoch 34/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5389 - accuracy: 0.7222 - val_loss: 0.5152 - val_accuracy: 0.7297\n",
            "Epoch 35/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7014 - val_loss: 0.5163 - val_accuracy: 0.7568\n",
            "Epoch 36/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7222 - val_loss: 0.5111 - val_accuracy: 0.7027\n",
            "Epoch 37/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5377 - accuracy: 0.7014 - val_loss: 0.5180 - val_accuracy: 0.7568\n",
            "Epoch 38/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5373 - accuracy: 0.7500 - val_loss: 0.5128 - val_accuracy: 0.7297\n",
            "Epoch 39/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5488 - accuracy: 0.6875 - val_loss: 0.5138 - val_accuracy: 0.7297\n",
            "Epoch 40/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5366 - accuracy: 0.7361 - val_loss: 0.5070 - val_accuracy: 0.6486\n",
            "Epoch 41/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5363 - accuracy: 0.7361 - val_loss: 0.5187 - val_accuracy: 0.7568\n",
            "Epoch 42/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5306 - accuracy: 0.7083 - val_loss: 0.5116 - val_accuracy: 0.7297\n",
            "Epoch 43/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5335 - accuracy: 0.7222 - val_loss: 0.5091 - val_accuracy: 0.7027\n",
            "Epoch 44/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5344 - accuracy: 0.7222 - val_loss: 0.5135 - val_accuracy: 0.7297\n",
            "Epoch 45/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5316 - accuracy: 0.7222 - val_loss: 0.5136 - val_accuracy: 0.7297\n",
            "Epoch 46/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5297 - accuracy: 0.7292 - val_loss: 0.5095 - val_accuracy: 0.7027\n",
            "Epoch 47/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5300 - accuracy: 0.7153 - val_loss: 0.5123 - val_accuracy: 0.7297\n",
            "Epoch 48/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5287 - accuracy: 0.7292 - val_loss: 0.5093 - val_accuracy: 0.7027\n",
            "Epoch 49/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5279 - accuracy: 0.7292 - val_loss: 0.5109 - val_accuracy: 0.7297\n",
            "Epoch 50/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5272 - accuracy: 0.7431 - val_loss: 0.5073 - val_accuracy: 0.7027\n",
            "Epoch 51/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5261 - accuracy: 0.7431 - val_loss: 0.5148 - val_accuracy: 0.7568\n",
            "Epoch 52/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5244 - accuracy: 0.7431 - val_loss: 0.5056 - val_accuracy: 0.6757\n",
            "Epoch 53/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5236 - accuracy: 0.7292 - val_loss: 0.5086 - val_accuracy: 0.7297\n",
            "Epoch 54/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5231 - accuracy: 0.7431 - val_loss: 0.5078 - val_accuracy: 0.7027\n",
            "Epoch 55/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5221 - accuracy: 0.7500 - val_loss: 0.5063 - val_accuracy: 0.6757\n",
            "Epoch 56/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5219 - accuracy: 0.7361 - val_loss: 0.5078 - val_accuracy: 0.7297\n",
            "Epoch 57/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5232 - accuracy: 0.7292 - val_loss: 0.5058 - val_accuracy: 0.7027\n",
            "Epoch 58/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7431 - val_loss: 0.5098 - val_accuracy: 0.7297\n",
            "Epoch 59/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7431 - val_loss: 0.5067 - val_accuracy: 0.7027\n",
            "Epoch 60/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5208 - accuracy: 0.7500 - val_loss: 0.5084 - val_accuracy: 0.7297\n",
            "Epoch 61/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5210 - accuracy: 0.7222 - val_loss: 0.5054 - val_accuracy: 0.7027\n",
            "Epoch 62/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5211 - accuracy: 0.7431 - val_loss: 0.5091 - val_accuracy: 0.7297\n",
            "Epoch 63/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5179 - accuracy: 0.7569 - val_loss: 0.5040 - val_accuracy: 0.7027\n",
            "Epoch 64/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5198 - accuracy: 0.7500 - val_loss: 0.5078 - val_accuracy: 0.7297\n",
            "Epoch 65/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7500 - val_loss: 0.5034 - val_accuracy: 0.7027\n",
            "Epoch 66/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5176 - accuracy: 0.7222 - val_loss: 0.5113 - val_accuracy: 0.7297\n",
            "Epoch 67/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5170 - accuracy: 0.7569 - val_loss: 0.5080 - val_accuracy: 0.7027\n",
            "Epoch 68/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5140 - accuracy: 0.7569 - val_loss: 0.5065 - val_accuracy: 0.7027\n",
            "Epoch 69/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5145 - accuracy: 0.7431 - val_loss: 0.5100 - val_accuracy: 0.7297\n",
            "Epoch 70/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5122 - accuracy: 0.7431 - val_loss: 0.5051 - val_accuracy: 0.7027\n",
            "Epoch 71/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5129 - accuracy: 0.7569 - val_loss: 0.5041 - val_accuracy: 0.7027\n",
            "Epoch 72/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5130 - accuracy: 0.7569 - val_loss: 0.5043 - val_accuracy: 0.6757\n",
            "Epoch 73/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5131 - accuracy: 0.7431 - val_loss: 0.5079 - val_accuracy: 0.7027\n",
            "Epoch 74/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5110 - accuracy: 0.7569 - val_loss: 0.5047 - val_accuracy: 0.6757\n",
            "Epoch 75/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7500 - val_loss: 0.5048 - val_accuracy: 0.7027\n",
            "Epoch 76/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5087 - accuracy: 0.7569 - val_loss: 0.5066 - val_accuracy: 0.6757\n",
            "Epoch 77/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.7569 - val_loss: 0.5045 - val_accuracy: 0.7027\n",
            "Epoch 78/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5123 - accuracy: 0.7639 - val_loss: 0.5072 - val_accuracy: 0.7027\n",
            "Epoch 79/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5115 - accuracy: 0.7639 - val_loss: 0.5047 - val_accuracy: 0.6757\n",
            "Epoch 80/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5074 - accuracy: 0.7778 - val_loss: 0.5097 - val_accuracy: 0.7297\n",
            "Epoch 81/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5085 - accuracy: 0.7569 - val_loss: 0.5063 - val_accuracy: 0.6757\n",
            "Epoch 82/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5056 - accuracy: 0.7569 - val_loss: 0.5052 - val_accuracy: 0.6757\n",
            "Epoch 83/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5070 - accuracy: 0.7569 - val_loss: 0.5124 - val_accuracy: 0.7297\n",
            "Epoch 84/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5092 - accuracy: 0.7569 - val_loss: 0.5043 - val_accuracy: 0.7027\n",
            "Epoch 85/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5106 - accuracy: 0.7500 - val_loss: 0.5018 - val_accuracy: 0.6757\n",
            "Epoch 86/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7500 - val_loss: 0.5183 - val_accuracy: 0.7838\n",
            "Epoch 87/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7708 - val_loss: 0.5092 - val_accuracy: 0.6757\n",
            "Epoch 88/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5045 - accuracy: 0.7500 - val_loss: 0.5050 - val_accuracy: 0.6757\n",
            "Epoch 89/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5044 - accuracy: 0.7639 - val_loss: 0.5039 - val_accuracy: 0.7027\n",
            "Epoch 90/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5029 - accuracy: 0.7639 - val_loss: 0.5096 - val_accuracy: 0.6757\n",
            "Epoch 91/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5052 - accuracy: 0.7708 - val_loss: 0.5075 - val_accuracy: 0.6757\n",
            "Epoch 92/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5030 - accuracy: 0.7500 - val_loss: 0.5093 - val_accuracy: 0.6757\n",
            "Epoch 93/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5004 - accuracy: 0.7639 - val_loss: 0.5115 - val_accuracy: 0.6757\n",
            "Epoch 94/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4998 - accuracy: 0.7431 - val_loss: 0.5132 - val_accuracy: 0.6757\n",
            "Epoch 95/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5050 - accuracy: 0.7569 - val_loss: 0.5092 - val_accuracy: 0.6757\n",
            "Epoch 96/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4983 - accuracy: 0.7708 - val_loss: 0.5193 - val_accuracy: 0.7838\n",
            "Epoch 97/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5006 - accuracy: 0.7431 - val_loss: 0.5121 - val_accuracy: 0.6757\n",
            "Epoch 98/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4991 - accuracy: 0.7847 - val_loss: 0.5077 - val_accuracy: 0.6757\n",
            "Epoch 99/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7708 - val_loss: 0.5081 - val_accuracy: 0.6757\n",
            "Epoch 100/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4962 - accuracy: 0.7708 - val_loss: 0.5123 - val_accuracy: 0.7027\n",
            "Epoch 101/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4982 - accuracy: 0.7708 - val_loss: 0.5167 - val_accuracy: 0.7297\n",
            "Epoch 102/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7500 - val_loss: 0.5140 - val_accuracy: 0.7027\n",
            "Epoch 103/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4973 - accuracy: 0.7639 - val_loss: 0.5143 - val_accuracy: 0.7027\n",
            "Epoch 104/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4971 - accuracy: 0.7639 - val_loss: 0.5046 - val_accuracy: 0.6757\n",
            "Epoch 105/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7778 - val_loss: 0.5128 - val_accuracy: 0.6757\n",
            "Epoch 106/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4939 - accuracy: 0.7778 - val_loss: 0.5103 - val_accuracy: 0.6757\n",
            "Epoch 107/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7708 - val_loss: 0.5107 - val_accuracy: 0.6757\n",
            "Epoch 108/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4924 - accuracy: 0.7778 - val_loss: 0.5087 - val_accuracy: 0.6757\n",
            "Epoch 109/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4926 - accuracy: 0.7569 - val_loss: 0.5140 - val_accuracy: 0.6757\n",
            "Epoch 110/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7431 - val_loss: 0.5125 - val_accuracy: 0.6757\n",
            "Epoch 111/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7639 - val_loss: 0.5091 - val_accuracy: 0.6757\n",
            "Epoch 112/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4946 - accuracy: 0.7639 - val_loss: 0.5088 - val_accuracy: 0.6757\n",
            "Epoch 113/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7708 - val_loss: 0.5194 - val_accuracy: 0.7568\n",
            "Epoch 114/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4923 - accuracy: 0.7569 - val_loss: 0.5104 - val_accuracy: 0.6757\n",
            "Epoch 115/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4876 - accuracy: 0.7639 - val_loss: 0.5168 - val_accuracy: 0.7297\n",
            "Epoch 116/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4882 - accuracy: 0.7639 - val_loss: 0.5109 - val_accuracy: 0.6757\n",
            "Epoch 117/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4911 - accuracy: 0.7708 - val_loss: 0.5108 - val_accuracy: 0.6757\n",
            "Epoch 118/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4907 - accuracy: 0.7569 - val_loss: 0.5298 - val_accuracy: 0.7838\n",
            "Epoch 119/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4852 - accuracy: 0.7708 - val_loss: 0.5054 - val_accuracy: 0.6757\n",
            "Epoch 120/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4883 - accuracy: 0.7639 - val_loss: 0.5085 - val_accuracy: 0.6757\n",
            "Epoch 121/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4888 - accuracy: 0.7778 - val_loss: 0.5156 - val_accuracy: 0.7027\n",
            "Epoch 122/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7500 - val_loss: 0.5071 - val_accuracy: 0.6757\n",
            "Epoch 123/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7708 - val_loss: 0.5105 - val_accuracy: 0.6486\n",
            "Epoch 124/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4880 - accuracy: 0.7361 - val_loss: 0.5106 - val_accuracy: 0.6757\n",
            "Epoch 125/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4853 - accuracy: 0.7778 - val_loss: 0.5109 - val_accuracy: 0.6757\n",
            "Epoch 126/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4835 - accuracy: 0.7708 - val_loss: 0.5157 - val_accuracy: 0.7027\n",
            "Epoch 127/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4859 - accuracy: 0.7708 - val_loss: 0.5084 - val_accuracy: 0.6757\n",
            "Epoch 128/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7847 - val_loss: 0.5071 - val_accuracy: 0.6757\n",
            "Epoch 129/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4837 - accuracy: 0.7778 - val_loss: 0.5103 - val_accuracy: 0.6216\n",
            "Epoch 130/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7500 - val_loss: 0.5115 - val_accuracy: 0.6486\n",
            "Epoch 131/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4811 - accuracy: 0.7708 - val_loss: 0.5092 - val_accuracy: 0.6757\n",
            "Epoch 132/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4809 - accuracy: 0.7778 - val_loss: 0.5127 - val_accuracy: 0.7027\n",
            "Epoch 133/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4802 - accuracy: 0.7708 - val_loss: 0.5128 - val_accuracy: 0.6757\n",
            "Epoch 134/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4857 - accuracy: 0.7708 - val_loss: 0.5103 - val_accuracy: 0.6486\n",
            "Epoch 135/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7917 - val_loss: 0.5122 - val_accuracy: 0.6757\n",
            "Epoch 136/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4850 - accuracy: 0.7569 - val_loss: 0.5174 - val_accuracy: 0.7297\n",
            "Epoch 137/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4881 - accuracy: 0.7569 - val_loss: 0.5060 - val_accuracy: 0.6486\n",
            "Epoch 138/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4812 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.7297\n",
            "Epoch 139/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4794 - accuracy: 0.7708 - val_loss: 0.5152 - val_accuracy: 0.6757\n",
            "Epoch 140/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4766 - accuracy: 0.7708 - val_loss: 0.5199 - val_accuracy: 0.7297\n",
            "Epoch 141/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4765 - accuracy: 0.7778 - val_loss: 0.5253 - val_accuracy: 0.7297\n",
            "Epoch 142/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.7639 - val_loss: 0.5100 - val_accuracy: 0.6757\n",
            "Epoch 143/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4764 - accuracy: 0.7778 - val_loss: 0.5191 - val_accuracy: 0.7297\n",
            "Epoch 144/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4756 - accuracy: 0.7778 - val_loss: 0.5109 - val_accuracy: 0.6486\n",
            "Epoch 145/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4756 - accuracy: 0.7778 - val_loss: 0.5182 - val_accuracy: 0.7027\n",
            "Epoch 146/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4734 - accuracy: 0.7847 - val_loss: 0.5114 - val_accuracy: 0.6486\n",
            "Epoch 147/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4732 - accuracy: 0.7708 - val_loss: 0.5127 - val_accuracy: 0.6486\n",
            "Epoch 148/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4759 - accuracy: 0.7778 - val_loss: 0.5302 - val_accuracy: 0.7568\n",
            "Epoch 149/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7778 - val_loss: 0.5159 - val_accuracy: 0.6757\n",
            "Epoch 150/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7847 - val_loss: 0.5217 - val_accuracy: 0.7027\n",
            "Epoch 151/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4935 - accuracy: 0.7778 - val_loss: 0.5371 - val_accuracy: 0.7568\n",
            "Epoch 152/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4720 - accuracy: 0.7708 - val_loss: 0.5143 - val_accuracy: 0.6486\n",
            "Epoch 153/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4704 - accuracy: 0.7708 - val_loss: 0.5226 - val_accuracy: 0.7297\n",
            "Epoch 154/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4735 - accuracy: 0.7917 - val_loss: 0.5252 - val_accuracy: 0.7297\n",
            "Epoch 155/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4702 - accuracy: 0.7917 - val_loss: 0.5152 - val_accuracy: 0.6486\n",
            "Epoch 156/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4707 - accuracy: 0.7917 - val_loss: 0.5113 - val_accuracy: 0.6757\n",
            "Epoch 157/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7778 - val_loss: 0.5186 - val_accuracy: 0.6757\n",
            "Epoch 158/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4721 - accuracy: 0.7708 - val_loss: 0.5176 - val_accuracy: 0.6757\n",
            "Epoch 159/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4681 - accuracy: 0.7708 - val_loss: 0.5214 - val_accuracy: 0.7027\n",
            "Epoch 160/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7847 - val_loss: 0.5165 - val_accuracy: 0.6486\n",
            "Epoch 161/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7917 - val_loss: 0.5139 - val_accuracy: 0.6486\n",
            "Epoch 162/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.7917 - val_loss: 0.5215 - val_accuracy: 0.7027\n",
            "Epoch 163/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4659 - accuracy: 0.7917 - val_loss: 0.5212 - val_accuracy: 0.7027\n",
            "Epoch 164/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4668 - accuracy: 0.7847 - val_loss: 0.5244 - val_accuracy: 0.7027\n",
            "Epoch 165/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4678 - accuracy: 0.7986 - val_loss: 0.5141 - val_accuracy: 0.6486\n",
            "Epoch 166/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7986 - val_loss: 0.5329 - val_accuracy: 0.7297\n",
            "Epoch 167/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4703 - accuracy: 0.7847 - val_loss: 0.5184 - val_accuracy: 0.6757\n",
            "Epoch 168/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4658 - accuracy: 0.7778 - val_loss: 0.5313 - val_accuracy: 0.7027\n",
            "Epoch 169/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4646 - accuracy: 0.7917 - val_loss: 0.5222 - val_accuracy: 0.7027\n",
            "Epoch 170/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7847 - val_loss: 0.5278 - val_accuracy: 0.7027\n",
            "Epoch 171/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4613 - accuracy: 0.7917 - val_loss: 0.5268 - val_accuracy: 0.7027\n",
            "Epoch 172/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7778 - val_loss: 0.5199 - val_accuracy: 0.6757\n",
            "Epoch 173/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4623 - accuracy: 0.7917 - val_loss: 0.5166 - val_accuracy: 0.6486\n",
            "Epoch 174/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4628 - accuracy: 0.7847 - val_loss: 0.5395 - val_accuracy: 0.7568\n",
            "Epoch 175/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7778 - val_loss: 0.5197 - val_accuracy: 0.6486\n",
            "Epoch 176/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4653 - accuracy: 0.7847 - val_loss: 0.5315 - val_accuracy: 0.7027\n",
            "Epoch 177/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4618 - accuracy: 0.7778 - val_loss: 0.5306 - val_accuracy: 0.7027\n",
            "Epoch 178/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4596 - accuracy: 0.7917 - val_loss: 0.5228 - val_accuracy: 0.6757\n",
            "Epoch 179/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4614 - accuracy: 0.7708 - val_loss: 0.5251 - val_accuracy: 0.7027\n",
            "Epoch 180/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4577 - accuracy: 0.7986 - val_loss: 0.5207 - val_accuracy: 0.6486\n",
            "Epoch 181/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4602 - accuracy: 0.7847 - val_loss: 0.5223 - val_accuracy: 0.7027\n",
            "Epoch 182/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4568 - accuracy: 0.7708 - val_loss: 0.5251 - val_accuracy: 0.6757\n",
            "Epoch 183/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.7917 - val_loss: 0.5252 - val_accuracy: 0.6757\n",
            "Epoch 184/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4550 - accuracy: 0.7847 - val_loss: 0.5258 - val_accuracy: 0.6757\n",
            "Epoch 185/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4559 - accuracy: 0.7847 - val_loss: 0.5267 - val_accuracy: 0.7027\n",
            "Epoch 186/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.8056 - val_loss: 0.5204 - val_accuracy: 0.6757\n",
            "Epoch 187/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7917 - val_loss: 0.5277 - val_accuracy: 0.6757\n",
            "Epoch 188/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4568 - accuracy: 0.7917 - val_loss: 0.5238 - val_accuracy: 0.6757\n",
            "Epoch 189/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4584 - accuracy: 0.7847 - val_loss: 0.5236 - val_accuracy: 0.6757\n",
            "Epoch 190/200\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4535 - accuracy: 0.7917 - val_loss: 0.5343 - val_accuracy: 0.7027\n",
            "Epoch 191/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.7986 - val_loss: 0.5301 - val_accuracy: 0.7027\n",
            "Epoch 192/200\n",
            "29/29 [==============================] - 0s 2ms/step - loss: 0.4537 - accuracy: 0.7917 - val_loss: 0.5318 - val_accuracy: 0.7297\n",
            "Epoch 193/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4520 - accuracy: 0.7847 - val_loss: 0.5242 - val_accuracy: 0.6757\n",
            "Epoch 194/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4574 - accuracy: 0.8056 - val_loss: 0.5238 - val_accuracy: 0.6757\n",
            "Epoch 195/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4626 - accuracy: 0.7986 - val_loss: 0.5195 - val_accuracy: 0.7027\n",
            "Epoch 196/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4491 - accuracy: 0.8056 - val_loss: 0.5286 - val_accuracy: 0.7027\n",
            "Epoch 197/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4462 - accuracy: 0.7986 - val_loss: 0.5315 - val_accuracy: 0.7297\n",
            "Epoch 198/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.8125 - val_loss: 0.5275 - val_accuracy: 0.6757\n",
            "Epoch 199/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.8056 - val_loss: 0.5355 - val_accuracy: 0.7027\n",
            "Epoch 200/200\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4466 - accuracy: 0.7986 - val_loss: 0.5274 - val_accuracy: 0.7297\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_results_new = model_new.evaluate(Xn_test, yn_test, verbose=1)\n",
        "print(f'Test results - Loss: {test_results_new[0]} - Accuracy: {test_results_new[1]*100}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wp8FeSDSkIeJ",
        "outputId": "67fdd7e1-1f21-4b3a-d889-ecdf9d45c340"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6434 - accuracy: 0.7174\n",
            "Test results - Loss: 0.6433664560317993 - Accuracy: 71.7391312122345%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## creating a function to create a model and fitting that particular data with the file path in it."
      ],
      "metadata": {
        "id": "EuUGEYW9k7tC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model(file_path, verbose, new_bool, epochs):\n",
        "    df_here = pd.read_csv(file_path)\n",
        "    df_here['win'] = df_here['win'].astype('int')\n",
        "    X = df_here[df_here.columns[1:-1]]\n",
        "    y = df_here['win']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
        "    model = Sequential()\n",
        "    if(not new_bool):\n",
        "        model.add(Dense(12, input_dim=X.shape[1], activation='relu'))\n",
        "        model.add(Dense(8, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "    else:\n",
        "        model.add(Dense(14, input_dim=X.shape[1], activation='relu'))\n",
        "        model.add(Dense(9, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "    loss_fn = keras.losses.BinaryCrossentropy()\n",
        "    model.compile(loss=loss_fn, optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "    history = model.fit(X_train, y_train, epochs=epochs, batch_size=5, verbose=verbose, validation_split=0.2)\n",
        "    test_results = model.evaluate(X_test, y_test, verbose=1)\n",
        "    print('=============================\\n')\n",
        "    print(f'Test results - Loss: {test_results[0]} - Accuracy: {test_results[1]*100}%')\n",
        "    return model, history, test_results"
      ],
      "metadata": {
        "id": "ZkZUHhaylE8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "check_model = get_model('/content/drive/MyDrive/ML_project_dataset/Final_Normalized_Features/England_features.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hQzlA_tfmtQA",
        "outputId": "614ee6a7-c26d-405e-e9eb-79c44eb69477"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 1s 9ms/step - loss: 0.6603 - accuracy: 0.6042 - val_loss: 0.6697 - val_accuracy: 0.5135\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6498 - accuracy: 0.6042 - val_loss: 0.6644 - val_accuracy: 0.5135\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6436 - accuracy: 0.6111 - val_loss: 0.6631 - val_accuracy: 0.5135\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6379 - accuracy: 0.5972 - val_loss: 0.6582 - val_accuracy: 0.5676\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.6111 - val_loss: 0.6623 - val_accuracy: 0.5135\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6218 - accuracy: 0.5972 - val_loss: 0.6540 - val_accuracy: 0.5946\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6154 - accuracy: 0.6597 - val_loss: 0.6519 - val_accuracy: 0.7027\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6063 - accuracy: 0.6875 - val_loss: 0.6500 - val_accuracy: 0.7027\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6000 - accuracy: 0.6667 - val_loss: 0.6484 - val_accuracy: 0.6757\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5930 - accuracy: 0.7153 - val_loss: 0.6470 - val_accuracy: 0.6757\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5869 - accuracy: 0.7083 - val_loss: 0.6416 - val_accuracy: 0.6757\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5790 - accuracy: 0.7153 - val_loss: 0.6386 - val_accuracy: 0.6757\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7014 - val_loss: 0.6374 - val_accuracy: 0.6757\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5685 - accuracy: 0.7083 - val_loss: 0.6372 - val_accuracy: 0.6757\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5618 - accuracy: 0.7083 - val_loss: 0.6364 - val_accuracy: 0.6216\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5574 - accuracy: 0.7153 - val_loss: 0.6348 - val_accuracy: 0.6216\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5517 - accuracy: 0.7014 - val_loss: 0.6361 - val_accuracy: 0.6216\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5455 - accuracy: 0.7222 - val_loss: 0.6369 - val_accuracy: 0.6216\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5417 - accuracy: 0.7014 - val_loss: 0.6345 - val_accuracy: 0.6216\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5385 - accuracy: 0.6944 - val_loss: 0.6347 - val_accuracy: 0.6216\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5355 - accuracy: 0.7083 - val_loss: 0.6359 - val_accuracy: 0.6216\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.7083 - val_loss: 0.6346 - val_accuracy: 0.6216\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5269 - accuracy: 0.7083 - val_loss: 0.6433 - val_accuracy: 0.6216\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5254 - accuracy: 0.7083 - val_loss: 0.6405 - val_accuracy: 0.6486\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5257 - accuracy: 0.7083 - val_loss: 0.6388 - val_accuracy: 0.6486\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5160 - accuracy: 0.7222 - val_loss: 0.6507 - val_accuracy: 0.6486\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5166 - accuracy: 0.7083 - val_loss: 0.6474 - val_accuracy: 0.6486\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5121 - accuracy: 0.7083 - val_loss: 0.6500 - val_accuracy: 0.6486\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5088 - accuracy: 0.7361 - val_loss: 0.6474 - val_accuracy: 0.6486\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5076 - accuracy: 0.7500 - val_loss: 0.6524 - val_accuracy: 0.6486\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5083 - accuracy: 0.7292 - val_loss: 0.6573 - val_accuracy: 0.6486\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5032 - accuracy: 0.7431 - val_loss: 0.6566 - val_accuracy: 0.6486\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5021 - accuracy: 0.7500 - val_loss: 0.6604 - val_accuracy: 0.6486\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5005 - accuracy: 0.7361 - val_loss: 0.6591 - val_accuracy: 0.6216\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4988 - accuracy: 0.7431 - val_loss: 0.6683 - val_accuracy: 0.6216\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4963 - accuracy: 0.7431 - val_loss: 0.6655 - val_accuracy: 0.6216\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4957 - accuracy: 0.7569 - val_loss: 0.6617 - val_accuracy: 0.6216\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7431 - val_loss: 0.6736 - val_accuracy: 0.5946\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4936 - accuracy: 0.7431 - val_loss: 0.6764 - val_accuracy: 0.5946\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4915 - accuracy: 0.7500 - val_loss: 0.6754 - val_accuracy: 0.5946\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4918 - accuracy: 0.7569 - val_loss: 0.6752 - val_accuracy: 0.5946\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4922 - accuracy: 0.7500 - val_loss: 0.6756 - val_accuracy: 0.5946\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4887 - accuracy: 0.7500 - val_loss: 0.6762 - val_accuracy: 0.5946\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4879 - accuracy: 0.7500 - val_loss: 0.6867 - val_accuracy: 0.5946\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4862 - accuracy: 0.7569 - val_loss: 0.6817 - val_accuracy: 0.5946\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4861 - accuracy: 0.7431 - val_loss: 0.6823 - val_accuracy: 0.5946\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4842 - accuracy: 0.7431 - val_loss: 0.6850 - val_accuracy: 0.5946\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7500 - val_loss: 0.6873 - val_accuracy: 0.5946\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4841 - accuracy: 0.7569 - val_loss: 0.6928 - val_accuracy: 0.5946\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7569 - val_loss: 0.6849 - val_accuracy: 0.5946\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4818 - accuracy: 0.7639 - val_loss: 0.6969 - val_accuracy: 0.5946\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4814 - accuracy: 0.7500 - val_loss: 0.6858 - val_accuracy: 0.6216\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4835 - accuracy: 0.7500 - val_loss: 0.6994 - val_accuracy: 0.5946\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7500 - val_loss: 0.6883 - val_accuracy: 0.6486\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4770 - accuracy: 0.7500 - val_loss: 0.7057 - val_accuracy: 0.5946\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7639 - val_loss: 0.7009 - val_accuracy: 0.5946\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.7639 - val_loss: 0.7000 - val_accuracy: 0.5946\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4753 - accuracy: 0.7569 - val_loss: 0.7045 - val_accuracy: 0.5946\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4790 - accuracy: 0.7431 - val_loss: 0.7023 - val_accuracy: 0.5946\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4752 - accuracy: 0.7639 - val_loss: 0.7057 - val_accuracy: 0.5946\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4741 - accuracy: 0.7569 - val_loss: 0.7036 - val_accuracy: 0.5946\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4748 - accuracy: 0.7569 - val_loss: 0.7064 - val_accuracy: 0.5946\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4728 - accuracy: 0.7569 - val_loss: 0.7084 - val_accuracy: 0.5946\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.7569 - val_loss: 0.7058 - val_accuracy: 0.5946\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4711 - accuracy: 0.7639 - val_loss: 0.7120 - val_accuracy: 0.5946\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4712 - accuracy: 0.7569 - val_loss: 0.7126 - val_accuracy: 0.5946\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4723 - accuracy: 0.7639 - val_loss: 0.7122 - val_accuracy: 0.5946\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4708 - accuracy: 0.7639 - val_loss: 0.7142 - val_accuracy: 0.5946\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4739 - accuracy: 0.7778 - val_loss: 0.7049 - val_accuracy: 0.6216\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4688 - accuracy: 0.7639 - val_loss: 0.7137 - val_accuracy: 0.5946\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4721 - accuracy: 0.7639 - val_loss: 0.7088 - val_accuracy: 0.5946\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4700 - accuracy: 0.7500 - val_loss: 0.7205 - val_accuracy: 0.5946\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4679 - accuracy: 0.7569 - val_loss: 0.7146 - val_accuracy: 0.5946\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4658 - accuracy: 0.7569 - val_loss: 0.7168 - val_accuracy: 0.5946\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4665 - accuracy: 0.7708 - val_loss: 0.7213 - val_accuracy: 0.5946\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4669 - accuracy: 0.7569 - val_loss: 0.7102 - val_accuracy: 0.5946\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4684 - accuracy: 0.7778 - val_loss: 0.7167 - val_accuracy: 0.5946\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4636 - accuracy: 0.7569 - val_loss: 0.7210 - val_accuracy: 0.5946\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7708 - val_loss: 0.7179 - val_accuracy: 0.5946\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4629 - accuracy: 0.7639 - val_loss: 0.7208 - val_accuracy: 0.5946\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4647 - accuracy: 0.7500 - val_loss: 0.7244 - val_accuracy: 0.5946\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4624 - accuracy: 0.7708 - val_loss: 0.7265 - val_accuracy: 0.5946\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4611 - accuracy: 0.7569 - val_loss: 0.7240 - val_accuracy: 0.5946\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4644 - accuracy: 0.7708 - val_loss: 0.7317 - val_accuracy: 0.6216\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7639 - val_loss: 0.7273 - val_accuracy: 0.6216\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7917 - val_loss: 0.7248 - val_accuracy: 0.5946\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4634 - accuracy: 0.7569 - val_loss: 0.7291 - val_accuracy: 0.6216\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4594 - accuracy: 0.7708 - val_loss: 0.7217 - val_accuracy: 0.5946\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4566 - accuracy: 0.7639 - val_loss: 0.7316 - val_accuracy: 0.6216\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4620 - accuracy: 0.7847 - val_loss: 0.7301 - val_accuracy: 0.6216\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4586 - accuracy: 0.7639 - val_loss: 0.7270 - val_accuracy: 0.5946\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4547 - accuracy: 0.7639 - val_loss: 0.7354 - val_accuracy: 0.6216\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7708 - val_loss: 0.7290 - val_accuracy: 0.6216\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4551 - accuracy: 0.7847 - val_loss: 0.7361 - val_accuracy: 0.6216\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4608 - accuracy: 0.7639 - val_loss: 0.7344 - val_accuracy: 0.6216\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4543 - accuracy: 0.7917 - val_loss: 0.7336 - val_accuracy: 0.6216\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.7847 - val_loss: 0.7370 - val_accuracy: 0.6216\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4582 - accuracy: 0.7708 - val_loss: 0.7287 - val_accuracy: 0.5946\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4542 - accuracy: 0.7917 - val_loss: 0.7382 - val_accuracy: 0.6216\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4522 - accuracy: 0.7708 - val_loss: 0.7326 - val_accuracy: 0.6216\n",
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6294 - accuracy: 0.6522\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.6293655633926392 - Accuracy: 65.21739363670349%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "check_model_old = get_model('/content/drive/MyDrive/ML_project_dataset/Final_Normalized_Features/England_features.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RxAafgHcm-93",
        "outputId": "782bf7d1-db4f-47c6-954e-50187217f2cf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29/29 [==============================] - 1s 9ms/step - loss: 0.6808 - accuracy: 0.5556 - val_loss: 0.6621 - val_accuracy: 0.5946\n",
            "Epoch 2/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6690 - accuracy: 0.5556 - val_loss: 0.6517 - val_accuracy: 0.5946\n",
            "Epoch 3/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6587 - accuracy: 0.5625 - val_loss: 0.6426 - val_accuracy: 0.5946\n",
            "Epoch 4/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6491 - accuracy: 0.5625 - val_loss: 0.6371 - val_accuracy: 0.5946\n",
            "Epoch 5/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.5556 - val_loss: 0.6308 - val_accuracy: 0.5946\n",
            "Epoch 6/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6324 - accuracy: 0.5833 - val_loss: 0.6230 - val_accuracy: 0.6216\n",
            "Epoch 7/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6246 - accuracy: 0.7153 - val_loss: 0.6148 - val_accuracy: 0.5946\n",
            "Epoch 8/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6138 - accuracy: 0.7083 - val_loss: 0.6059 - val_accuracy: 0.5676\n",
            "Epoch 9/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.6055 - accuracy: 0.6944 - val_loss: 0.5982 - val_accuracy: 0.5946\n",
            "Epoch 10/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5947 - accuracy: 0.7014 - val_loss: 0.5900 - val_accuracy: 0.6216\n",
            "Epoch 11/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5866 - accuracy: 0.7292 - val_loss: 0.5828 - val_accuracy: 0.6216\n",
            "Epoch 12/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5799 - accuracy: 0.7292 - val_loss: 0.5750 - val_accuracy: 0.6757\n",
            "Epoch 13/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5722 - accuracy: 0.7222 - val_loss: 0.5698 - val_accuracy: 0.6486\n",
            "Epoch 14/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5639 - accuracy: 0.7222 - val_loss: 0.5635 - val_accuracy: 0.6216\n",
            "Epoch 15/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5571 - accuracy: 0.7361 - val_loss: 0.5570 - val_accuracy: 0.6486\n",
            "Epoch 16/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5510 - accuracy: 0.7292 - val_loss: 0.5520 - val_accuracy: 0.7027\n",
            "Epoch 17/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5483 - accuracy: 0.7639 - val_loss: 0.5474 - val_accuracy: 0.7027\n",
            "Epoch 18/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5424 - accuracy: 0.7431 - val_loss: 0.5474 - val_accuracy: 0.6486\n",
            "Epoch 19/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5374 - accuracy: 0.7500 - val_loss: 0.5456 - val_accuracy: 0.7027\n",
            "Epoch 20/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5339 - accuracy: 0.7639 - val_loss: 0.5412 - val_accuracy: 0.7027\n",
            "Epoch 21/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.5286 - accuracy: 0.7500 - val_loss: 0.5361 - val_accuracy: 0.7027\n",
            "Epoch 22/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5290 - accuracy: 0.7639 - val_loss: 0.5388 - val_accuracy: 0.7027\n",
            "Epoch 23/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5215 - accuracy: 0.7361 - val_loss: 0.5296 - val_accuracy: 0.7027\n",
            "Epoch 24/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5199 - accuracy: 0.7500 - val_loss: 0.5293 - val_accuracy: 0.6757\n",
            "Epoch 25/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5185 - accuracy: 0.7569 - val_loss: 0.5284 - val_accuracy: 0.7027\n",
            "Epoch 26/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5162 - accuracy: 0.7569 - val_loss: 0.5273 - val_accuracy: 0.7027\n",
            "Epoch 27/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5138 - accuracy: 0.7639 - val_loss: 0.5267 - val_accuracy: 0.7027\n",
            "Epoch 28/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5126 - accuracy: 0.7500 - val_loss: 0.5244 - val_accuracy: 0.7027\n",
            "Epoch 29/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5093 - accuracy: 0.7569 - val_loss: 0.5232 - val_accuracy: 0.7027\n",
            "Epoch 30/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5073 - accuracy: 0.7708 - val_loss: 0.5252 - val_accuracy: 0.7027\n",
            "Epoch 31/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5054 - accuracy: 0.7639 - val_loss: 0.5210 - val_accuracy: 0.7027\n",
            "Epoch 32/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5069 - accuracy: 0.7639 - val_loss: 0.5204 - val_accuracy: 0.7027\n",
            "Epoch 33/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5063 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.7027\n",
            "Epoch 34/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5033 - accuracy: 0.7569 - val_loss: 0.5228 - val_accuracy: 0.7297\n",
            "Epoch 35/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5016 - accuracy: 0.7708 - val_loss: 0.5201 - val_accuracy: 0.6757\n",
            "Epoch 36/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.5042 - accuracy: 0.7361 - val_loss: 0.5234 - val_accuracy: 0.7027\n",
            "Epoch 37/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4984 - accuracy: 0.7639 - val_loss: 0.5237 - val_accuracy: 0.7027\n",
            "Epoch 38/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4976 - accuracy: 0.7569 - val_loss: 0.5225 - val_accuracy: 0.7027\n",
            "Epoch 39/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4968 - accuracy: 0.7500 - val_loss: 0.5184 - val_accuracy: 0.6757\n",
            "Epoch 40/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4943 - accuracy: 0.7569 - val_loss: 0.5207 - val_accuracy: 0.7027\n",
            "Epoch 41/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4956 - accuracy: 0.7500 - val_loss: 0.5207 - val_accuracy: 0.7027\n",
            "Epoch 42/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4940 - accuracy: 0.7500 - val_loss: 0.5205 - val_accuracy: 0.7027\n",
            "Epoch 43/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4931 - accuracy: 0.7569 - val_loss: 0.5196 - val_accuracy: 0.6757\n",
            "Epoch 44/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4913 - accuracy: 0.7431 - val_loss: 0.5204 - val_accuracy: 0.6757\n",
            "Epoch 45/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4900 - accuracy: 0.7569 - val_loss: 0.5193 - val_accuracy: 0.6757\n",
            "Epoch 46/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4897 - accuracy: 0.7569 - val_loss: 0.5192 - val_accuracy: 0.6757\n",
            "Epoch 47/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4934 - accuracy: 0.7431 - val_loss: 0.5176 - val_accuracy: 0.6757\n",
            "Epoch 48/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4866 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.6757\n",
            "Epoch 49/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7639 - val_loss: 0.5199 - val_accuracy: 0.7027\n",
            "Epoch 50/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4871 - accuracy: 0.7500 - val_loss: 0.5180 - val_accuracy: 0.6757\n",
            "Epoch 51/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4846 - accuracy: 0.7361 - val_loss: 0.5179 - val_accuracy: 0.6757\n",
            "Epoch 52/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4831 - accuracy: 0.7500 - val_loss: 0.5203 - val_accuracy: 0.7027\n",
            "Epoch 53/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4836 - accuracy: 0.7500 - val_loss: 0.5182 - val_accuracy: 0.7027\n",
            "Epoch 54/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4863 - accuracy: 0.7361 - val_loss: 0.5228 - val_accuracy: 0.7027\n",
            "Epoch 55/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7639 - val_loss: 0.5186 - val_accuracy: 0.7027\n",
            "Epoch 56/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4817 - accuracy: 0.7500 - val_loss: 0.5176 - val_accuracy: 0.6757\n",
            "Epoch 57/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4804 - accuracy: 0.7569 - val_loss: 0.5183 - val_accuracy: 0.6757\n",
            "Epoch 58/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4825 - accuracy: 0.7500 - val_loss: 0.5177 - val_accuracy: 0.6757\n",
            "Epoch 59/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4807 - accuracy: 0.7569 - val_loss: 0.5210 - val_accuracy: 0.7027\n",
            "Epoch 60/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4760 - accuracy: 0.7500 - val_loss: 0.5188 - val_accuracy: 0.7027\n",
            "Epoch 61/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4792 - accuracy: 0.7500 - val_loss: 0.5249 - val_accuracy: 0.7027\n",
            "Epoch 62/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4723 - accuracy: 0.7639 - val_loss: 0.5204 - val_accuracy: 0.7027\n",
            "Epoch 63/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4779 - accuracy: 0.7569 - val_loss: 0.5201 - val_accuracy: 0.6757\n",
            "Epoch 64/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4714 - accuracy: 0.7500 - val_loss: 0.5238 - val_accuracy: 0.7027\n",
            "Epoch 65/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4763 - accuracy: 0.7569 - val_loss: 0.5214 - val_accuracy: 0.7027\n",
            "Epoch 66/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4744 - accuracy: 0.7500 - val_loss: 0.5279 - val_accuracy: 0.7027\n",
            "Epoch 67/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7431 - val_loss: 0.5214 - val_accuracy: 0.7027\n",
            "Epoch 68/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4722 - accuracy: 0.7431 - val_loss: 0.5253 - val_accuracy: 0.7027\n",
            "Epoch 69/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4712 - accuracy: 0.7639 - val_loss: 0.5251 - val_accuracy: 0.7027\n",
            "Epoch 70/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4661 - accuracy: 0.7500 - val_loss: 0.5261 - val_accuracy: 0.7027\n",
            "Epoch 71/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7569 - val_loss: 0.5259 - val_accuracy: 0.7027\n",
            "Epoch 72/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4771 - accuracy: 0.7292 - val_loss: 0.5208 - val_accuracy: 0.7027\n",
            "Epoch 73/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4682 - accuracy: 0.7569 - val_loss: 0.5261 - val_accuracy: 0.7027\n",
            "Epoch 74/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4642 - accuracy: 0.7500 - val_loss: 0.5227 - val_accuracy: 0.7297\n",
            "Epoch 75/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4660 - accuracy: 0.7500 - val_loss: 0.5256 - val_accuracy: 0.7297\n",
            "Epoch 76/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4632 - accuracy: 0.7569 - val_loss: 0.5257 - val_accuracy: 0.7297\n",
            "Epoch 77/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4662 - accuracy: 0.7569 - val_loss: 0.5252 - val_accuracy: 0.7297\n",
            "Epoch 78/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4625 - accuracy: 0.7500 - val_loss: 0.5316 - val_accuracy: 0.7297\n",
            "Epoch 79/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4595 - accuracy: 0.7569 - val_loss: 0.5229 - val_accuracy: 0.7297\n",
            "Epoch 80/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4600 - accuracy: 0.7639 - val_loss: 0.5225 - val_accuracy: 0.7027\n",
            "Epoch 81/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4610 - accuracy: 0.7639 - val_loss: 0.5261 - val_accuracy: 0.7297\n",
            "Epoch 82/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4599 - accuracy: 0.7569 - val_loss: 0.5268 - val_accuracy: 0.7297\n",
            "Epoch 83/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4552 - accuracy: 0.7500 - val_loss: 0.5201 - val_accuracy: 0.7297\n",
            "Epoch 84/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4560 - accuracy: 0.7569 - val_loss: 0.5272 - val_accuracy: 0.7027\n",
            "Epoch 85/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4540 - accuracy: 0.7639 - val_loss: 0.5267 - val_accuracy: 0.7297\n",
            "Epoch 86/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4556 - accuracy: 0.7639 - val_loss: 0.5172 - val_accuracy: 0.6757\n",
            "Epoch 87/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7639 - val_loss: 0.5285 - val_accuracy: 0.7297\n",
            "Epoch 88/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4523 - accuracy: 0.7639 - val_loss: 0.5259 - val_accuracy: 0.7027\n",
            "Epoch 89/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4504 - accuracy: 0.7639 - val_loss: 0.5245 - val_accuracy: 0.7297\n",
            "Epoch 90/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4514 - accuracy: 0.7639 - val_loss: 0.5219 - val_accuracy: 0.7297\n",
            "Epoch 91/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4498 - accuracy: 0.7569 - val_loss: 0.5270 - val_accuracy: 0.7027\n",
            "Epoch 92/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4483 - accuracy: 0.7778 - val_loss: 0.5230 - val_accuracy: 0.7297\n",
            "Epoch 93/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4490 - accuracy: 0.7708 - val_loss: 0.5230 - val_accuracy: 0.7297\n",
            "Epoch 94/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4477 - accuracy: 0.7708 - val_loss: 0.5290 - val_accuracy: 0.7027\n",
            "Epoch 95/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4488 - accuracy: 0.7847 - val_loss: 0.5225 - val_accuracy: 0.7297\n",
            "Epoch 96/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4464 - accuracy: 0.7778 - val_loss: 0.5238 - val_accuracy: 0.7027\n",
            "Epoch 97/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4451 - accuracy: 0.7778 - val_loss: 0.5223 - val_accuracy: 0.7297\n",
            "Epoch 98/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4431 - accuracy: 0.7778 - val_loss: 0.5263 - val_accuracy: 0.7027\n",
            "Epoch 99/100\n",
            "29/29 [==============================] - 0s 4ms/step - loss: 0.4467 - accuracy: 0.7639 - val_loss: 0.5319 - val_accuracy: 0.7027\n",
            "Epoch 100/100\n",
            "29/29 [==============================] - 0s 3ms/step - loss: 0.4481 - accuracy: 0.7778 - val_loss: 0.5252 - val_accuracy: 0.7027\n",
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7357 - accuracy: 0.5870\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.7356804609298706 - Accuracy: 58.69565010070801%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Now checking for all the datasets and creating separate dictionaries with models and the values for training and testing accuracy."
      ],
      "metadata": {
        "id": "w5aZd6pBM5UI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def get_final_results(regular_path, new_path, country_list, countries_regular):\n",
        "    regular_data_dict = {}      #storing accuracy for training and testing\n",
        "    regular_model_dict = {}\n",
        "    regular_data_dict['country'] = countries_regular\n",
        "    regular_data_dict['train acc'] = []\n",
        "    regular_data_dict['test loss'] = []\n",
        "    regular_data_dict['test acc'] = []\n",
        "    for country in country_list:\n",
        "        path_here = regular_path + country\n",
        "        model, history, test_results = get_model(path_here, 0, 0, 150)\n",
        "        regular_model_dict[country[:country.find('_')]] = model\n",
        "        regular_data_dict['train acc'].append(max(history.history['val_accuracy']))\n",
        "        regular_data_dict['test loss'].append(test_results[0])\n",
        "        regular_data_dict['test acc'].append(test_results[1]*100)\n",
        "\n",
        "    new_data_dict = {}      #storing accuracy for training and testing\n",
        "    new_model_dict = {}\n",
        "    new_data_dict['country'] = countries_regular\n",
        "    new_data_dict['train acc'] = []\n",
        "    new_data_dict['test loss'] = []\n",
        "    new_data_dict['test acc'] = []\n",
        "    for country in country_list:\n",
        "        path_here = new_path + country\n",
        "        model, history, test_results = get_model(path_here, 0, 1, 250)\n",
        "        new_model_dict[country[:country.find('_')]] = model\n",
        "        new_data_dict['train acc'].append(max(history.history['val_accuracy']))\n",
        "        new_data_dict['test loss'].append(test_results[0])\n",
        "        new_data_dict['test acc'].append(test_results[1]*100)\n",
        "    \n",
        "    return regular_data_dict, regular_model_dict, new_data_dict, new_model_dict"
      ],
      "metadata": {
        "id": "dYNTmEsZNdI9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regular_data_dict, regular_model_dict, new_data_dict, new_model_dict = get_final_results(regular_feature_path, new_feature_path, country_name_list, countries_regular)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J681JSxduvNX",
        "outputId": "228b9b16-26df-437a-92e2-ec6ccab0ec47"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.4020 - accuracy: 0.8387\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.40195009112358093 - Accuracy: 83.87096524238586%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.4015 - accuracy: 0.8286\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.40148410201072693 - Accuracy: 82.85714387893677%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7819 - accuracy: 0.6667\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.7818692326545715 - Accuracy: 66.66666865348816%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5812 - accuracy: 0.7250\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5811710953712463 - Accuracy: 72.50000238418579%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 114ms/step - loss: 0.7538 - accuracy: 0.5312\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.7537935972213745 - Accuracy: 53.125%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5934 - accuracy: 0.6757\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5934443473815918 - Accuracy: 67.56756901741028%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6947 - accuracy: 0.6000\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.6947205662727356 - Accuracy: 60.00000238418579%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8001 - accuracy: 0.6757\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.8001019954681396 - Accuracy: 67.56756901741028%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.5646 - accuracy: 0.6800\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5645695924758911 - Accuracy: 68.00000071525574%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5381 - accuracy: 0.7368\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5380842089653015 - Accuracy: 73.68420958518982%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5697 - accuracy: 0.6774\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5696609020233154 - Accuracy: 67.7419364452362%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8498 - accuracy: 0.6000\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.8498289585113525 - Accuracy: 60.00000238418579%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.7535 - accuracy: 0.5385\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.7534905672073364 - Accuracy: 53.84615659713745%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9183 - accuracy: 0.6000\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.9182685613632202 - Accuracy: 60.00000238418579%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 0.6567 - accuracy: 0.7188\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.6567495465278625 - Accuracy: 71.875%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0523 - accuracy: 0.5405\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 1.0523451566696167 - Accuracy: 54.054051637649536%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.7035 - accuracy: 0.6286\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.7034599184989929 - Accuracy: 62.85714507102966%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7309 - accuracy: 0.6216\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.7308675646781921 - Accuracy: 62.162160873413086%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.8162 - accuracy: 0.7200\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.8161890506744385 - Accuracy: 72.00000286102295%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8873 - accuracy: 0.6053\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.8873383402824402 - Accuracy: 60.52631735801697%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regular_data_dict.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Np5t6SmYycnF",
        "outputId": "48e276d5-9eed-43ad-af5a-07434c6695c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['country', 'train acc', 'test loss', 'test acc'])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(regular_data_dict['test loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RJhOu6P6ywIn",
        "outputId": "696d0009-748f-49a2-8f3c-a2fa20c228b7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "regular_table = pd.DataFrame.from_dict(regular_data_dict)"
      ],
      "metadata": {
        "id": "sv0qfoEBr_-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_table = pd.DataFrame.from_dict(new_data_dict)"
      ],
      "metadata": {
        "id": "cAa_UtUozNUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "regular_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "7xYFbh2ZzGj5",
        "outputId": "be64fc64-d9a9-49e2-f3dd-7b903b9ecb91"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       country  train acc  test loss   test acc\n",
              "0      Belgium   0.617647   0.401950  83.870965\n",
              "1      England   0.692308   0.401484  82.857144\n",
              "2       France   0.688889   0.781869  66.666669\n",
              "3      Germany   0.630435   0.581171  72.500002\n",
              "4       Greece   0.666667   0.753794  53.125000\n",
              "5        Italy   0.658537   0.593444  67.567569\n",
              "6  Netherlands   0.675000   0.694721  60.000002\n",
              "7     Portugal   0.785714   0.800102  67.567569\n",
              "8     Scotland   0.714286   0.564570  68.000001\n",
              "9        Spain   0.744186   0.538084  73.684210"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f959f098-f09d-4b6f-983e-f7b2ccc47bac\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>train acc</th>\n",
              "      <th>test loss</th>\n",
              "      <th>test acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Belgium</td>\n",
              "      <td>0.617647</td>\n",
              "      <td>0.401950</td>\n",
              "      <td>83.870965</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>England</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.401484</td>\n",
              "      <td>82.857144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>France</td>\n",
              "      <td>0.688889</td>\n",
              "      <td>0.781869</td>\n",
              "      <td>66.666669</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Germany</td>\n",
              "      <td>0.630435</td>\n",
              "      <td>0.581171</td>\n",
              "      <td>72.500002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Greece</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.753794</td>\n",
              "      <td>53.125000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Italy</td>\n",
              "      <td>0.658537</td>\n",
              "      <td>0.593444</td>\n",
              "      <td>67.567569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Netherlands</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.694721</td>\n",
              "      <td>60.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Portugal</td>\n",
              "      <td>0.785714</td>\n",
              "      <td>0.800102</td>\n",
              "      <td>67.567569</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Scotland</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.564570</td>\n",
              "      <td>68.000001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Spain</td>\n",
              "      <td>0.744186</td>\n",
              "      <td>0.538084</td>\n",
              "      <td>73.684210</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f959f098-f09d-4b6f-983e-f7b2ccc47bac')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f959f098-f09d-4b6f-983e-f7b2ccc47bac button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f959f098-f09d-4b6f-983e-f7b2ccc47bac');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "dXIJLjYNzXG2",
        "outputId": "70a16574-7a79-4934-b578-971a111a1e6c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       country  train acc  test loss   test acc\n",
              "0      Belgium   0.823529   0.569661  67.741936\n",
              "1      England   0.717949   0.849829  60.000002\n",
              "2       France   0.711111   0.753491  53.846157\n",
              "3      Germany   0.630435   0.918269  60.000002\n",
              "4       Greece   0.777778   0.656750  71.875000\n",
              "5        Italy   0.682927   1.052345  54.054052\n",
              "6  Netherlands   0.675000   0.703460  62.857145\n",
              "7     Portugal   0.714286   0.730868  62.162161\n",
              "8     Scotland   0.857143   0.816189  72.000003\n",
              "9        Spain   0.790698   0.887338  60.526317"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5eb59eea-954e-4df8-b77b-285f282f288f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>country</th>\n",
              "      <th>train acc</th>\n",
              "      <th>test loss</th>\n",
              "      <th>test acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Belgium</td>\n",
              "      <td>0.823529</td>\n",
              "      <td>0.569661</td>\n",
              "      <td>67.741936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>England</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.849829</td>\n",
              "      <td>60.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>France</td>\n",
              "      <td>0.711111</td>\n",
              "      <td>0.753491</td>\n",
              "      <td>53.846157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Germany</td>\n",
              "      <td>0.630435</td>\n",
              "      <td>0.918269</td>\n",
              "      <td>60.000002</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Greece</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.656750</td>\n",
              "      <td>71.875000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Italy</td>\n",
              "      <td>0.682927</td>\n",
              "      <td>1.052345</td>\n",
              "      <td>54.054052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Netherlands</td>\n",
              "      <td>0.675000</td>\n",
              "      <td>0.703460</td>\n",
              "      <td>62.857145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Portugal</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.730868</td>\n",
              "      <td>62.162161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Scotland</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.816189</td>\n",
              "      <td>72.000003</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Spain</td>\n",
              "      <td>0.790698</td>\n",
              "      <td>0.887338</td>\n",
              "      <td>60.526317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5eb59eea-954e-4df8-b77b-285f282f288f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5eb59eea-954e-4df8-b77b-285f282f288f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5eb59eea-954e-4df8-b77b-285f282f288f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ablation testing:"
      ],
      "metadata": {
        "id": "DNtHFj0OyL-4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results_one_count(path_type, country_name, epochs, verbose):\n",
        "    df_here = pd.read_csv(path_type + country_name)\n",
        "    df_here['win'] = df_here['win'].astype('int')\n",
        "    column_names = df_here.columns[1:-1]\n",
        "    ablation_dict = {}\n",
        "    ablation_dict['feature'] = column_names\n",
        "    ablation_dict['train acc'] = []\n",
        "    ablation_dict['test loss'] = []\n",
        "    ablation_dict['test acc'] = []\n",
        "    for feature in column_names:\n",
        "        df_here = pd.read_csv(path_type + country_name)\n",
        "        df_here['win'] = df_here['win'].astype('int')\n",
        "        X = df_here[df_here.columns[1:-1]]\n",
        "        del X[feature]\n",
        "        y = df_here['win']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
        "        model = Sequential()\n",
        "        model.add(Dense(12, input_dim=X.shape[1], activation='relu'))\n",
        "        model.add(Dense(8, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        loss_fn = keras.losses.BinaryCrossentropy()\n",
        "        model.compile(loss=loss_fn, optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=5, verbose=verbose, validation_split=0.2)\n",
        "        test_results = model.evaluate(X_test, y_test, verbose=1)\n",
        "        ablation_dict['train acc'].append(max(history.history['val_accuracy']))\n",
        "        ablation_dict['test loss'].append(test_results[0])\n",
        "        ablation_dict['test acc'].append(test_results[1]*100)\n",
        "    return ablation_dict\n"
      ],
      "metadata": {
        "id": "lcR0QK0hyShl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ablation_dict = get_results_one_count(regular_feature_path, 'England_features.csv', 150, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s5Se1C151bmd",
        "outputId": "fd99fd20-c574-483f-b6c4-83c514971876"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4974 - accuracy: 0.7714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6427 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5002 - accuracy: 0.7714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8249 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5495 - accuracy: 0.7714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5515 - accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5569 - accuracy: 0.7429\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ablation_table = pd.DataFrame.from_dict(ablation_dict)\n",
        "ablation_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "a8wAkyjP2R1c",
        "outputId": "d4e4e838-4591-44b3-e926-ee2757853cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           feature  train acc  test loss   test acc\n",
              "0        team_rank   0.717949   0.497418  77.142859\n",
              "1        rank_diff   0.564103   0.642654  62.857145\n",
              "2         win_rate   0.769231   0.500172  77.142859\n",
              "3  Team_Venue_Form   0.769231   0.824871  62.857145\n",
              "4   Opp_Venue_Form   0.846154   0.549460  77.142859\n",
              "5    Team_Cumul_GD   0.717949   0.551458  65.714288\n",
              "6     Opp_Cumul_GD   0.692308   0.556918  74.285716"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8e1dda1a-3198-4a4b-ae4f-b2d9e9f166f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>train acc</th>\n",
              "      <th>test loss</th>\n",
              "      <th>test acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>team_rank</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.497418</td>\n",
              "      <td>77.142859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rank_diff</td>\n",
              "      <td>0.564103</td>\n",
              "      <td>0.642654</td>\n",
              "      <td>62.857145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>win_rate</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.500172</td>\n",
              "      <td>77.142859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Team_Venue_Form</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.824871</td>\n",
              "      <td>62.857145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Opp_Venue_Form</td>\n",
              "      <td>0.846154</td>\n",
              "      <td>0.549460</td>\n",
              "      <td>77.142859</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Team_Cumul_GD</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.551458</td>\n",
              "      <td>65.714288</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Opp_Cumul_GD</td>\n",
              "      <td>0.692308</td>\n",
              "      <td>0.556918</td>\n",
              "      <td>74.285716</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8e1dda1a-3198-4a4b-ae4f-b2d9e9f166f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8e1dda1a-3198-4a4b-ae4f-b2d9e9f166f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8e1dda1a-3198-4a4b-ae4f-b2d9e9f166f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for country in country_name_list:\n",
        "    ablation_dict = get_results_one_count(regular_feature_path, country, 150, 0)\n",
        "    ablation_table = pd.DataFrame.from_dict(ablation_dict)\n",
        "    print(country[:country.find('_')])\n",
        "    print(ablation_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8fGMpZpO2vf9",
        "outputId": "c061ad60-8686-4de1-d906-95fe245db53c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6601 - accuracy: 0.5806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.7417 - accuracy: 0.5484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.4881 - accuracy: 0.7097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.6858 - accuracy: 0.6129\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5196 - accuracy: 0.7419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6851 - accuracy: 0.6452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.7072 - accuracy: 0.6129\n",
            "Belgium\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.764706   0.660077  58.064514\n",
            "1        rank_diff   0.676471   0.741694  54.838711\n",
            "2         win_rate   0.676471   0.488085  70.967740\n",
            "3  Team_Venue_Form   0.617647   0.685824  61.290324\n",
            "4   Opp_Venue_Form   0.735294   0.519644  74.193549\n",
            "5    Team_Cumul_GD   0.794118   0.685079  64.516127\n",
            "6     Opp_Cumul_GD   0.823529   0.707202  61.290324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4717 - accuracy: 0.7714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7088 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6415 - accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5623 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7437 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6574 - accuracy: 0.6857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.4984 - accuracy: 0.8286\n",
            "England\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.769231   0.471735  77.142859\n",
            "1        rank_diff   0.666667   0.708825  62.857145\n",
            "2         win_rate   0.820513   0.641455  65.714288\n",
            "3  Team_Venue_Form   0.666667   0.562311  80.000001\n",
            "4   Opp_Venue_Form   0.743590   0.743656  62.857145\n",
            "5    Team_Cumul_GD   0.769231   0.657353  68.571430\n",
            "6     Opp_Cumul_GD   0.666667   0.498356  82.857144\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5787 - accuracy: 0.6410\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5935 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6238 - accuracy: 0.6154\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5684 - accuracy: 0.6667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7401 - accuracy: 0.6923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5981 - accuracy: 0.6923\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6770 - accuracy: 0.5641\n",
            "France\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.688889   0.578699  64.102566\n",
            "1        rank_diff   0.711111   0.593486  66.666669\n",
            "2         win_rate   0.800000   0.623843  61.538464\n",
            "3  Team_Venue_Form   0.733333   0.568419  66.666669\n",
            "4   Opp_Venue_Form   0.666667   0.740143  69.230771\n",
            "5    Team_Cumul_GD   0.755556   0.598149  69.230771\n",
            "6     Opp_Cumul_GD   0.822222   0.676967  56.410259\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5626 - accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5484 - accuracy: 0.7250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7281 - accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5123 - accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.6792 - accuracy: 0.5750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6593 - accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7179 - accuracy: 0.6250\n",
            "Germany\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.695652   0.562578  64.999998\n",
            "1        rank_diff   0.652174   0.548431  72.500002\n",
            "2         win_rate   0.695652   0.728128  64.999998\n",
            "3  Team_Venue_Form   0.695652   0.512317  62.500000\n",
            "4   Opp_Venue_Form   0.782609   0.679242  57.499999\n",
            "5    Team_Cumul_GD   0.782609   0.659339  64.999998\n",
            "6     Opp_Cumul_GD   0.760870   0.717930  62.500000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step - loss: 0.6367 - accuracy: 0.6562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 108ms/step - loss: 0.7566 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 0.6780 - accuracy: 0.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 116ms/step - loss: 0.4562 - accuracy: 0.7812\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 111ms/step - loss: 0.8120 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 115ms/step - loss: 0.8183 - accuracy: 0.5312\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 107ms/step - loss: 0.6861 - accuracy: 0.6562\n",
            "Greece\n",
            "           feature  train acc  test loss  test acc\n",
            "0        team_rank   0.666667   0.636660    65.625\n",
            "1        rank_diff   0.750000   0.756614    50.000\n",
            "2         win_rate   0.722222   0.677958    68.750\n",
            "3  Team_Venue_Form   0.694444   0.456249    78.125\n",
            "4   Opp_Venue_Form   0.694444   0.812021    50.000\n",
            "5    Team_Cumul_GD   0.555556   0.818311    53.125\n",
            "6     Opp_Cumul_GD   0.694444   0.686109    65.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7750 - accuracy: 0.4865\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6630 - accuracy: 0.6486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7178 - accuracy: 0.6486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6433 - accuracy: 0.6216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8131 - accuracy: 0.4324\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7958 - accuracy: 0.6216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5996 - accuracy: 0.6486\n",
            "Italy\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.756098   0.775019  48.648649\n",
            "1        rank_diff   0.682927   0.663039  64.864862\n",
            "2         win_rate   0.682927   0.717759  64.864862\n",
            "3  Team_Venue_Form   0.585366   0.643350  62.162161\n",
            "4   Opp_Venue_Form   0.609756   0.813134  43.243244\n",
            "5    Team_Cumul_GD   0.634146   0.795761  62.162161\n",
            "6     Opp_Cumul_GD   0.634146   0.599636  64.864862\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5503 - accuracy: 0.6857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6128 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5733 - accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6463 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5237 - accuracy: 0.8000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5483 - accuracy: 0.7429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5228 - accuracy: 0.6857\n",
            "Netherlands\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank      0.725   0.550287  68.571430\n",
            "1        rank_diff      0.800   0.612755  71.428573\n",
            "2         win_rate      0.800   0.573304  65.714288\n",
            "3  Team_Venue_Form      0.825   0.646291  71.428573\n",
            "4   Opp_Venue_Form      0.850   0.523684  80.000001\n",
            "5    Team_Cumul_GD      0.700   0.548320  74.285716\n",
            "6     Opp_Cumul_GD      0.725   0.522787  68.571430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5576 - accuracy: 0.7838\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7717 - accuracy: 0.5405\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6843 - accuracy: 0.6757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5970 - accuracy: 0.7027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6467 - accuracy: 0.6757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7421 - accuracy: 0.6216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5494 - accuracy: 0.7568\n",
            "Portugal\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.690476   0.557566  78.378379\n",
            "1        rank_diff   0.738095   0.771686  54.054052\n",
            "2         win_rate   0.666667   0.684332  67.567569\n",
            "3  Team_Venue_Form   0.761905   0.596992  70.270270\n",
            "4   Opp_Venue_Form   0.714286   0.646695  67.567569\n",
            "5    Team_Cumul_GD   0.666667   0.742064  62.162161\n",
            "6     Opp_Cumul_GD   0.714286   0.549413  75.675678\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 0.6467 - accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 25ms/step - loss: 0.6252 - accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 22ms/step - loss: 0.5614 - accuracy: 0.7600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.6616 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.6297 - accuracy: 0.7200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5490 - accuracy: 0.7200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.2926 - accuracy: 0.9200\n",
            "Scotland\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.750000   0.646671  68.000001\n",
            "1        rank_diff   0.785714   0.625209  68.000001\n",
            "2         win_rate   0.821429   0.561372  75.999999\n",
            "3  Team_Venue_Form   0.857143   0.661593  60.000002\n",
            "4   Opp_Venue_Form   0.750000   0.629679  72.000003\n",
            "5    Team_Cumul_GD   0.785714   0.548976  72.000003\n",
            "6     Opp_Cumul_GD   0.928571   0.292625  92.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7692 - accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6354 - accuracy: 0.6842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7534 - accuracy: 0.6316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7005 - accuracy: 0.7105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6674 - accuracy: 0.6842\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6837 - accuracy: 0.7105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5046 - accuracy: 0.7368\n",
            "Spain\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.813953   0.769163  65.789473\n",
            "1        rank_diff   0.720930   0.635394  68.421054\n",
            "2         win_rate   0.744186   0.753384  63.157892\n",
            "3  Team_Venue_Form   0.744186   0.700509  71.052629\n",
            "4   Opp_Venue_Form   0.837209   0.667443  68.421054\n",
            "5    Team_Cumul_GD   0.767442   0.683748  71.052629\n",
            "6     Opp_Cumul_GD   0.720930   0.504622  73.684210\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### making a seperate function for the new features and checking the ablation."
      ],
      "metadata": {
        "id": "I-c6UhSwTkQ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results_one_count_new_feat(path_type, country_name, epochs, verbose):\n",
        "    df_here = pd.read_csv(path_type + country_name)\n",
        "    df_here['win'] = df_here['win'].astype('int')\n",
        "    column_names = df_here.columns[1:-1]\n",
        "    ablation_dict = {}\n",
        "    ablation_dict['feature'] = column_names\n",
        "    ablation_dict['train acc'] = []\n",
        "    ablation_dict['test loss'] = []\n",
        "    ablation_dict['test acc'] = []\n",
        "    for feature in column_names:\n",
        "        df_here = pd.read_csv(path_type + country_name)\n",
        "        df_here['win'] = df_here['win'].astype('int')\n",
        "        X = df_here[df_here.columns[1:-1]]\n",
        "        del X[feature]\n",
        "        y = df_here['win']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
        "        model = Sequential()\n",
        "        model.add(Dense(14, input_dim=X.shape[1], activation='relu'))\n",
        "        model.add(Dense(10, activation='relu'))\n",
        "        model.add(Dense(4, activation = \"relu\"))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        loss_fn = keras.losses.BinaryCrossentropy()\n",
        "        model.compile(loss=loss_fn, optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=5, verbose=verbose, validation_split=0.2)\n",
        "        test_results = model.evaluate(X_test, y_test, verbose=1)\n",
        "        ablation_dict['train acc'].append(max(history.history['val_accuracy']))\n",
        "        ablation_dict['test loss'].append(test_results[0])\n",
        "        ablation_dict['test acc'].append(test_results[1]*100)\n",
        "    return ablation_dict"
      ],
      "metadata": {
        "id": "q6IEpmTYTNcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for country in country_name_list:\n",
        "    ablation_dict = get_results_one_count_new_feat(new_feature_path, country, 250, 0)\n",
        "    ablation_table = pd.DataFrame.from_dict(ablation_dict)\n",
        "    print(country[:country.find('_')])\n",
        "    print(ablation_table)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bDZTlc1MSzo-",
        "outputId": "b9c26017-00b7-439c-f97c-f35cd1d9c311"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.5746 - accuracy: 0.6452\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8000 - accuracy: 0.5484\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 1.2033 - accuracy: 0.7097\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7960 - accuracy: 0.5806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step - loss: 0.8773 - accuracy: 0.5806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1899 - accuracy: 0.5806\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.6803 - accuracy: 0.7419\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 20ms/step - loss: 0.9174 - accuracy: 0.6774\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8336 - accuracy: 0.7742\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 19ms/step - loss: 0.5638 - accuracy: 0.7742\n",
            "Belgium\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.647059   0.574591  64.516127\n",
            "1        rank_diff   0.617647   0.799989  54.838711\n",
            "2         win_rate   0.823529   1.203344  70.967740\n",
            "3  Team_Venue_Form   0.852941   1.796003  58.064514\n",
            "4   Opp_Venue_Form   0.852941   0.877335  58.064514\n",
            "5    Team_Cumul_GD   0.794118   1.189944  58.064514\n",
            "6     Opp_Cumul_GD   0.676471   0.680318  74.193549\n",
            "7        Total_exp   0.617647   0.917414  67.741936\n",
            "8  Total_Exp_local   0.735294   0.833556  77.419353\n",
            "9  Total_Exp_youth   0.794118   0.563824  77.419353\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9261 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6812 - accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7186 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8743 - accuracy: 0.5429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8582 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9266 - accuracy: 0.5429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8855 - accuracy: 0.6571\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7225 - accuracy: 0.6857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6257 - accuracy: 0.6000\n",
            "England\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.589744   0.926112  60.000002\n",
            "1        rank_diff   0.666667   0.681245  65.714288\n",
            "2         win_rate   0.769231   0.718600  71.428573\n",
            "3  Team_Venue_Form   0.769231   0.874328  54.285717\n",
            "4   Opp_Venue_Form   0.769231   0.858185  62.857145\n",
            "5    Team_Cumul_GD   0.820513   0.596918  65.714288\n",
            "6     Opp_Cumul_GD   0.820513   0.926610  54.285717\n",
            "7        Total_exp   0.589744   0.885534  65.714288\n",
            "8  Total_Exp_local   0.769231   0.722458  68.571430\n",
            "9  Total_Exp_youth   0.743590   0.625651  60.000002\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 1.0428 - accuracy: 0.5897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8633 - accuracy: 0.5897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6396 - accuracy: 0.7436\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 1.4459 - accuracy: 0.5128\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6289 - accuracy: 0.5897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6022 - accuracy: 0.7179\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6711 - accuracy: 0.5897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8914 - accuracy: 0.5897\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 1.1907 - accuracy: 0.4872\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.8882 - accuracy: 0.4359\n",
            "France\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.688889   1.042783  58.974361\n",
            "1        rank_diff   0.777778   0.863277  58.974361\n",
            "2         win_rate   0.711111   0.639614  74.358976\n",
            "3  Team_Venue_Form   0.755556   1.445856  51.282054\n",
            "4   Opp_Venue_Form   0.666667   0.628907  58.974361\n",
            "5    Team_Cumul_GD   0.711111   0.602170  71.794873\n",
            "6     Opp_Cumul_GD   0.688889   0.671086  58.974361\n",
            "7        Total_exp   0.577778   0.891438  58.974361\n",
            "8  Total_Exp_local   0.733333   1.190697  48.717949\n",
            "9  Total_Exp_youth   0.777778   0.888198  43.589744\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7987 - accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 1.2687 - accuracy: 0.5500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5405 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5312 - accuracy: 0.7000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.9138 - accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6910 - accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9701 - accuracy: 0.5500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 2.3050 - accuracy: 0.6500\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0530 - accuracy: 0.4750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.5805 - accuracy: 0.7500\n",
            "Germany\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.630435   0.798742  62.500000\n",
            "1        rank_diff   0.717391   1.268747  55.000001\n",
            "2         win_rate   0.782609   0.540547  69.999999\n",
            "3  Team_Venue_Form   0.673913   0.531234  69.999999\n",
            "4   Opp_Venue_Form   0.782609   0.913816  64.999998\n",
            "5    Team_Cumul_GD   0.717391   0.690967  62.500000\n",
            "6     Opp_Cumul_GD   0.717391   0.970100  55.000001\n",
            "7        Total_exp   0.717391   2.304965  64.999998\n",
            "8  Total_Exp_local   0.760870   1.053045  47.499999\n",
            "9  Total_Exp_youth   0.673913   0.580482  75.000000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step - loss: 0.8737 - accuracy: 0.5938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 114ms/step - loss: 0.8141 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step - loss: 0.8655 - accuracy: 0.5938\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 113ms/step - loss: 1.0978 - accuracy: 0.6250\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 111ms/step - loss: 1.4293 - accuracy: 0.5000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 106ms/step - loss: 1.3072 - accuracy: 0.3750\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 118ms/step - loss: 0.7209 - accuracy: 0.6562\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 115ms/step - loss: 0.6095 - accuracy: 0.7188\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step - loss: 0.7835 - accuracy: 0.6875\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 110ms/step - loss: 0.8847 - accuracy: 0.6562\n",
            "Greece\n",
            "           feature  train acc  test loss  test acc\n",
            "0        team_rank   0.638889   0.873741    59.375\n",
            "1        rank_diff   0.611111   0.814062    50.000\n",
            "2         win_rate   0.666667   0.865511    59.375\n",
            "3  Team_Venue_Form   0.666667   1.097827    62.500\n",
            "4   Opp_Venue_Form   0.638889   1.429349    50.000\n",
            "5    Team_Cumul_GD   0.888889   1.307178    37.500\n",
            "6     Opp_Cumul_GD   0.638889   0.720939    65.625\n",
            "7        Total_exp   0.583333   0.609495    71.875\n",
            "8  Total_Exp_local   0.666667   0.783451    68.750\n",
            "9  Total_Exp_youth   0.722222   0.884713    65.625\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2807 - accuracy: 0.5135\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.9547 - accuracy: 0.4595\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7565 - accuracy: 0.6757\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6203 - accuracy: 0.6216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.9455 - accuracy: 0.5676\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8125 - accuracy: 0.5946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0216 - accuracy: 0.5946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 1.3081 - accuracy: 0.3784\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.0610 - accuracy: 0.6216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7901 - accuracy: 0.6216\n",
            "Italy\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.682927   1.280747  51.351351\n",
            "1        rank_diff   0.682927   0.954691  45.945945\n",
            "2         win_rate   0.780488   0.756501  67.567569\n",
            "3  Team_Venue_Form   0.707317   0.620277  62.162161\n",
            "4   Opp_Venue_Form   0.682927   0.945490  56.756759\n",
            "5    Team_Cumul_GD   0.609756   0.812488  59.459460\n",
            "6     Opp_Cumul_GD   0.780488   1.021560  59.459460\n",
            "7        Total_exp   0.707317   1.308070  37.837839\n",
            "8  Total_Exp_local   0.609756   1.060975  62.162161\n",
            "9  Total_Exp_youth   0.634146   0.790109  62.162161\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7485 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.7935 - accuracy: 0.5714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1219 - accuracy: 0.5429\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5868 - accuracy: 0.7714\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.8299 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.9682 - accuracy: 0.6857\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7460 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5494 - accuracy: 0.7143\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.7901 - accuracy: 0.6286\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.3364 - accuracy: 0.6857\n",
            "Netherlands\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank      0.775   0.748535  60.000002\n",
            "1        rank_diff      0.700   0.793509  57.142860\n",
            "2         win_rate      0.700   1.121887  54.285717\n",
            "3  Team_Venue_Form      0.775   0.586818  77.142859\n",
            "4   Opp_Venue_Form      0.725   0.829891  62.857145\n",
            "5    Team_Cumul_GD      0.800   0.968238  68.571430\n",
            "6     Opp_Cumul_GD      0.700   0.745967  62.857145\n",
            "7        Total_exp      0.900   0.549390  71.428573\n",
            "8  Total_Exp_local      0.750   0.790127  62.857145\n",
            "9  Total_Exp_youth      0.775   1.336380  68.571430\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.8048 - accuracy: 0.6486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7055 - accuracy: 0.7568\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6583 - accuracy: 0.6486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 1.2980 - accuracy: 0.6486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7344 - accuracy: 0.7297\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.7295 - accuracy: 0.7027\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.9599 - accuracy: 0.5946\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 1.0663 - accuracy: 0.6216\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 1.1258 - accuracy: 0.6486\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 1.6858 - accuracy: 0.5405\n",
            "Portugal\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.761905   0.804799  64.864862\n",
            "1        rank_diff   0.666667   0.705540  75.675678\n",
            "2         win_rate   0.738095   0.658298  64.864862\n",
            "3  Team_Venue_Form   0.619048   1.297950  64.864862\n",
            "4   Opp_Venue_Form   0.714286   0.734446  72.972971\n",
            "5    Team_Cumul_GD   0.595238   0.729458  70.270270\n",
            "6     Opp_Cumul_GD   0.738095   0.959859  59.459460\n",
            "7        Total_exp   0.666667   1.066281  62.162161\n",
            "8  Total_Exp_local   0.833333   1.125845  64.864862\n",
            "9  Total_Exp_youth   0.761905   1.685752  54.054052\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7689 - accuracy: 0.7200\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8146 - accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5806 - accuracy: 0.6400\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 1.1910 - accuracy: 0.7600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7227 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.8962 - accuracy: 0.5600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 17ms/step - loss: 0.7091 - accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 16ms/step - loss: 0.4818 - accuracy: 0.7600\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.7401 - accuracy: 0.6000\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 18ms/step - loss: 0.8423 - accuracy: 0.7200\n",
            "Scotland\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.821429   0.768945  72.000003\n",
            "1        rank_diff   0.642857   0.814570  68.000001\n",
            "2         win_rate   0.678571   0.580646  63.999999\n",
            "3  Team_Venue_Form   0.750000   1.190954  75.999999\n",
            "4   Opp_Venue_Form   0.750000   0.722708  60.000002\n",
            "5    Team_Cumul_GD   0.785714   0.896184  56.000000\n",
            "6     Opp_Cumul_GD   0.714286   0.709100  68.000001\n",
            "7        Total_exp   0.750000   0.481819  75.999999\n",
            "8  Total_Exp_local   0.785714   0.740114  60.000002\n",
            "9  Total_Exp_youth   0.750000   0.842305  72.000003\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6441 - accuracy: 0.7368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.5485 - accuracy: 0.7368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6815 - accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.8174 - accuracy: 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6658 - accuracy: 0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.8551 - accuracy: 0.6053\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6710 - accuracy: 0.7368\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.8444 - accuracy: 0.7105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 1.4716 - accuracy: 0.5526\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6207 - accuracy: 0.6053\n",
            "Spain\n",
            "           feature  train acc  test loss   test acc\n",
            "0        team_rank   0.674419   0.644123  73.684210\n",
            "1        rank_diff   0.813953   0.548452  73.684210\n",
            "2         win_rate   0.767442   0.681513  65.789473\n",
            "3  Team_Venue_Form   0.860465   0.817392  55.263156\n",
            "4   Opp_Venue_Form   0.697674   0.665768  60.526317\n",
            "5    Team_Cumul_GD   0.813953   0.855131  60.526317\n",
            "6     Opp_Cumul_GD   0.674419   0.671002  73.684210\n",
            "7        Total_exp   0.720930   0.844438  71.052629\n",
            "8  Total_Exp_local   0.720930   1.471630  55.263156\n",
            "9  Total_Exp_youth   0.930233   0.620729  60.526317\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "another function for ablation(only top nations and seeing the relavance with respect to the real life results.)"
      ],
      "metadata": {
        "id": "PbZndPp4iAY4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_results_one_count_regularnn(path_type, country_name, epochs, verbose):\n",
        "    df_here = pd.read_csv(path_type + country_name)\n",
        "    df_here['win'] = df_here['win'].astype('int')\n",
        "    column_names = df_here.columns[1:-1]\n",
        "    ablation_dict = {}\n",
        "    ablation_dict['feature'] = column_names\n",
        "    ablation_dict['train acc'] = []\n",
        "    ablation_dict['test loss'] = []\n",
        "    ablation_dict['test acc'] = []\n",
        "    for feature in column_names:\n",
        "        df_here = pd.read_csv(path_type + country_name)\n",
        "        df_here['win'] = df_here['win'].astype('int')\n",
        "        X = df_here[df_here.columns[1:-1]]\n",
        "        del X[feature]\n",
        "        y = df_here['win']\n",
        "        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15)\n",
        "        model = Sequential()\n",
        "        model.add(Dense(14, input_dim=X.shape[1], activation='relu'))\n",
        "        model.add(Dense(10, activation='relu'))\n",
        "        model.add(Dense(1, activation='sigmoid'))\n",
        "        loss_fn = keras.losses.BinaryCrossentropy()\n",
        "        model.compile(loss=loss_fn, optimizer=keras.optimizers.Adam(lr=0.001), metrics=['accuracy'])\n",
        "        history = model.fit(X_train, y_train, epochs=epochs, batch_size=5, verbose=verbose, validation_split=0.2)\n",
        "        test_results = model.evaluate(X_test, y_test, verbose=1)\n",
        "        ablation_dict['train acc'].append(max(history.history['val_accuracy']))\n",
        "        ablation_dict['test loss'].append(test_results[0])\n",
        "        ablation_dict['test acc'].append(test_results[1]*100)\n",
        "    return ablation_dict"
      ],
      "metadata": {
        "id": "d8SV3yKVd6DJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "spain_ablation_dict = get_results_one_count_regularnn(new_feature_path, 'Spain_features.csv', 225, 0)\n",
        "spain_ablation_table = pd.DataFrame.from_dict(ablation_dict)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkWDKQYPeRwc",
        "outputId": "c71e05b3-f2ea-4f90-8f25-4ae45017ffbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7583 - accuracy: 0.6316\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.6433 - accuracy: 0.7105\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 3ms/step - loss: 0.7260 - accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.5423 - accuracy: 0.7632\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.4672 - accuracy: 0.8158\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.6563 - accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 1.0179 - accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 5ms/step - loss: 0.7487 - accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 6ms/step - loss: 0.6911 - accuracy: 0.6579\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.5841 - accuracy: 0.7105\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spain_ablation_table"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 359
        },
        "id": "kU8xqWUffyuV",
        "outputId": "909db63b-6c68-47b2-fd68-4108bb17a1fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           feature  train acc  test loss   test acc\n",
              "0        team_rank   0.674419   0.644123  73.684210\n",
              "1        rank_diff   0.813953   0.548452  73.684210\n",
              "2         win_rate   0.767442   0.681513  65.789473\n",
              "3  Team_Venue_Form   0.860465   0.817392  55.263156\n",
              "4   Opp_Venue_Form   0.697674   0.665768  60.526317\n",
              "5    Team_Cumul_GD   0.813953   0.855131  60.526317\n",
              "6     Opp_Cumul_GD   0.674419   0.671002  73.684210\n",
              "7        Total_exp   0.720930   0.844438  71.052629\n",
              "8  Total_Exp_local   0.720930   1.471630  55.263156\n",
              "9  Total_Exp_youth   0.930233   0.620729  60.526317"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-e859c497-fbfb-4f48-a5f7-c9884448e92a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>feature</th>\n",
              "      <th>train acc</th>\n",
              "      <th>test loss</th>\n",
              "      <th>test acc</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>team_rank</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.644123</td>\n",
              "      <td>73.684210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>rank_diff</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.548452</td>\n",
              "      <td>73.684210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>win_rate</td>\n",
              "      <td>0.767442</td>\n",
              "      <td>0.681513</td>\n",
              "      <td>65.789473</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Team_Venue_Form</td>\n",
              "      <td>0.860465</td>\n",
              "      <td>0.817392</td>\n",
              "      <td>55.263156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Opp_Venue_Form</td>\n",
              "      <td>0.697674</td>\n",
              "      <td>0.665768</td>\n",
              "      <td>60.526317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Team_Cumul_GD</td>\n",
              "      <td>0.813953</td>\n",
              "      <td>0.855131</td>\n",
              "      <td>60.526317</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>Opp_Cumul_GD</td>\n",
              "      <td>0.674419</td>\n",
              "      <td>0.671002</td>\n",
              "      <td>73.684210</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Total_exp</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>0.844438</td>\n",
              "      <td>71.052629</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>Total_Exp_local</td>\n",
              "      <td>0.720930</td>\n",
              "      <td>1.471630</td>\n",
              "      <td>55.263156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>Total_Exp_youth</td>\n",
              "      <td>0.930233</td>\n",
              "      <td>0.620729</td>\n",
              "      <td>60.526317</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e859c497-fbfb-4f48-a5f7-c9884448e92a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e859c497-fbfb-4f48-a5f7-c9884448e92a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e859c497-fbfb-4f48-a5f7-c9884448e92a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss_list = []\n",
        "val_loss_list = []\n",
        "for country in country_name_list:\n",
        "    model, history, test_results = get_model(regular_feature_path + country, 0, 0, 200)\n",
        "    loss_list.append(history.history['loss'])\n",
        "    val_loss_list.append(history.history['val_loss'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RXqcziNx4AQU",
        "outputId": "d1c24d6e-1d28-41d2-bbd7-c5c31e7c90c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 24ms/step - loss: 0.7227 - accuracy: 0.6774\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.7226709127426147 - Accuracy: 67.7419364452362%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.6335 - accuracy: 0.6857\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.6335217952728271 - Accuracy: 68.57143044471741%\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 8ms/step - loss: 0.6453 - accuracy: 0.6923\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.6453178524971008 - Accuracy: 69.2307710647583%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 10ms/step - loss: 0.5621 - accuracy: 0.6000\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5621463060379028 - Accuracy: 60.00000238418579%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step - loss: 0.6182 - accuracy: 0.6562\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.6181834936141968 - Accuracy: 65.625%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 7ms/step - loss: 0.6295 - accuracy: 0.6216\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.6294623613357544 - Accuracy: 62.162160873413086%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 0.5118 - accuracy: 0.8000\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5117939114570618 - Accuracy: 80.0000011920929%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 9ms/step - loss: 1.0687 - accuracy: 0.6216\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 1.0687419176101685 - Accuracy: 62.162160873413086%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 21ms/step - loss: 0.5090 - accuracy: 0.8000\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.5090062618255615 - Accuracy: 80.0000011920929%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/adam.py:105: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 4ms/step - loss: 0.4669 - accuracy: 0.7895\n",
            "=============================\n",
            "\n",
            "Test results - Loss: 0.46692100167274475 - Accuracy: 78.94737124443054%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "countries_regular_copy = ['Belgium', 'England','France', 'Germany', 'Greece', 'Italy', 'Netherlands', 'Portugal',\n",
        "                     'Scotland', 'Spain']\n",
        "#plt.gca().set_color_cycle(['brown', 'red', 'blue', 'yellow', 'violet', 'green', 'orange', 'maroon', 'gold', 'brown'])\n",
        "k = len(loss_list[0])\n",
        "print(k)\n",
        "for loss in loss_list:\n",
        "    plt.plot(k, loss)\n",
        "\n",
        "plt.legend(countries_regular_copy, loc = 'upper left')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 644
        },
        "id": "6xT5-fwv5il2",
        "outputId": "bd14fded-5466-446d-ff0f-b98185b80cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "200\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-20e735308dc1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcountries_regular_copy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'upper left'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/pyplot.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2761\u001b[0m     return gca().plot(\n\u001b[1;32m   2762\u001b[0m         *args, scalex=scalex, scaley=scaley, **({\"data\": data} if data\n\u001b[0;32m-> 2763\u001b[0;31m         is not None else {}), **kwargs)\n\u001b[0m\u001b[1;32m   2764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2765\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_axes.py\u001b[0m in \u001b[0;36mplot\u001b[0;34m(self, scalex, scaley, data, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1645\u001b[0m         \"\"\"\n\u001b[1;32m   1646\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcbook\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize_kwargs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmlines\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLine2D\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1647\u001b[0;31m         \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_lines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1648\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1649\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_line\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                 \u001b[0mthis\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m                 \u001b[0margs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_plot_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_next_color\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/matplotlib/axes/_base.py\u001b[0m in \u001b[0;36m_plot_args\u001b[0;34m(self, tup, kwargs)\u001b[0m\n\u001b[1;32m    340\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 342\u001b[0;31m             raise ValueError(f\"x and y must have same first dimension, but \"\n\u001b[0m\u001b[1;32m    343\u001b[0m                              f\"have shapes {x.shape} and {y.shape}\")\n\u001b[1;32m    344\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: x and y must have same first dimension, but have shapes (1,) and (200,)"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXwAAAD8CAYAAAB0IB+mAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAANT0lEQVR4nO3cYYjkd33H8ffHO1NpjKb0VpC706T00njYQtIlTRFqirZc8uDugUXuIFgleGAbKVWEFEuU+MiGWhCu1ZOKVdAYfSALntwDjQTEC7chNXgXItvTeheFrDHNk6Ax7bcPZtKdrneZf3Zndy/7fb/gYP7/+e3Mlx97752d2ZlUFZKk7e8VWz2AJGlzGHxJasLgS1ITBl+SmjD4ktSEwZekJqYGP8lnkzyZ5PuXuD5JPplkKcmjSW6c/ZiSpPUa8gj/c8CBF7n+VmDf+N9R4F/WP5YkadamBr+qHgR+/iJLDgGfr5FTwNVJXj+rASVJs7FzBrexGzg/cXxhfO6nqxcmOcrotwCuvPLKP7z++utncPeS1MfDDz/8s6qaW8vXziL4g1XVceA4wPz8fC0uLm7m3UvSy16S/1zr187ir3SeAPZOHO8Zn5MkXUZmEfwF4F3jv9a5GXimqn7t6RxJ0taa+pROki8BtwC7klwAPgK8EqCqPgWcAG4DloBngfds1LCSpLWbGvyqOjLl+gL+emYTSZI2hO+0laQmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqYlBwU9yIMnjSZaS3HWR69+Q5IEkjyR5NMltsx9VkrQeU4OfZAdwDLgV2A8cSbJ/1bK/B+6vqhuAw8A/z3pQSdL6DHmEfxOwVFXnquo54D7g0Ko1BbxmfPm1wE9mN6IkaRaGBH83cH7i+ML43KSPArcnuQCcAN5/sRtKcjTJYpLF5eXlNYwrSVqrWb1oewT4XFXtAW4DvpDk1267qo5X1XxVzc/Nzc3oriVJQwwJ/hPA3onjPeNzk+4A7geoqu8CrwJ2zWJASdJsDAn+aWBfkmuTXMHoRdmFVWt+DLwNIMmbGAXf52wk6TIyNfhV9TxwJ3ASeIzRX+OcSXJPkoPjZR8E3pvke8CXgHdXVW3U0JKkl27nkEVVdYLRi7GT5+6euHwWeMtsR5MkzZLvtJWkJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNTEo+EkOJHk8yVKSuy6x5p1JziY5k+SLsx1TkrReO6ctSLIDOAb8GXABOJ1koarOTqzZB/wd8JaqejrJ6zZqYEnS2gx5hH8TsFRV56rqOeA+4NCqNe8FjlXV0wBV9eRsx5QkrdeQ4O8Gzk8cXxifm3QdcF2S7yQ5leTAxW4oydEki0kWl5eX1zaxJGlNZvWi7U5gH3ALcAT4TJKrVy+qquNVNV9V83NzczO6a0nSEEOC/wSwd+J4z/jcpAvAQlX9qqp+CPyA0Q8ASdJlYkjwTwP7klyb5ArgMLCwas3XGD26J8kuRk/xnJvhnJKkdZoa/Kp6HrgTOAk8BtxfVWeS3JPk4HjZSeCpJGeBB4APVdVTGzW0JOmlS1VtyR3Pz8/X4uLilty3JL1cJXm4qubX8rW+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmBgU/yYEkjydZSnLXi6x7R5JKMj+7ESVJszA1+El2AMeAW4H9wJEk+y+y7irgb4CHZj2kJGn9hjzCvwlYqqpzVfUccB9w6CLrPgZ8HPjFDOeTJM3IkODvBs5PHF8Yn/s/SW4E9lbV11/shpIcTbKYZHF5efklDytJWrt1v2ib5BXAJ4APTltbVcerar6q5ufm5tZ715Kkl2BI8J8A9k4c7xmfe8FVwJuBbyf5EXAzsOALt5J0eRkS/NPAviTXJrkCOAwsvHBlVT1TVbuq6pqqugY4BRysqsUNmViStCZTg19VzwN3AieBx4D7q+pMknuSHNzoASVJs7FzyKKqOgGcWHXu7kusvWX9Y0mSZs132kpSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmhgU/CQHkjyeZCnJXRe5/gNJziZ5NMk3k7xx9qNKktZjavCT7ACOAbcC+4EjSfavWvYIMF9VfwB8FfiHWQ8qSVqfIY/wbwKWqupcVT0H3AccmlxQVQ9U1bPjw1PAntmOKUlaryHB3w2cnzi+MD53KXcA37jYFUmOJllMsri8vDx8SknSus30RdsktwPzwL0Xu76qjlfVfFXNz83NzfKuJUlT7Byw5glg78TxnvG5/yfJ24EPA2+tql/OZjxJ0qwMeYR/GtiX5NokVwCHgYXJBUluAD4NHKyqJ2c/piRpvaYGv6qeB+4ETgKPAfdX1Zkk9yQ5OF52L/Bq4CtJ/j3JwiVuTpK0RYY8pUNVnQBOrDp398Tlt894LknSjPlOW0lqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpow+JLUhMGXpCYMviQ1YfAlqQmDL0lNGHxJasLgS1ITBl+SmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElqwuBLUhMGX5KaMPiS1ITBl6QmDL4kNWHwJakJgy9JTRh8SWrC4EtSEwZfkpoYFPwkB5I8nmQpyV0Xuf43knx5fP1DSa6Z9aCSpPWZGvwkO4BjwK3AfuBIkv2rlt0BPF1Vvwv8E/DxWQ8qSVqfIY/wbwKWqupcVT0H3AccWrXmEPBv48tfBd6WJLMbU5K0XjsHrNkNnJ84vgD80aXWVNXzSZ4Bfhv42eSiJEeBo+PDXyb5/lqG3oZ2sWqvGnMvVrgXK9yLFb+31i8cEvyZqarjwHGAJItVNb+Z93+5ci9WuBcr3IsV7sWKJItr/dohT+k8AeydON4zPnfRNUl2Aq8FnlrrUJKk2RsS/NPAviTXJrkCOAwsrFqzAPzl+PJfAN+qqprdmJKk9Zr6lM74Ofk7gZPADuCzVXUmyT3AYlUtAP8KfCHJEvBzRj8Upjm+jrm3G/dihXuxwr1Y4V6sWPNexAfiktSD77SVpCYMviQ1seHB92MZVgzYiw8kOZvk0STfTPLGrZhzM0zbi4l170hSSbbtn+QN2Ysk7xx/b5xJ8sXNnnGzDPg/8oYkDyR5ZPz/5LatmHOjJflskicv9V6ljHxyvE+PJrlx0A1X1Yb9Y/Qi738AvwNcAXwP2L9qzV8BnxpfPgx8eSNn2qp/A/fiT4HfHF9+X+e9GK+7CngQOAXMb/XcW/h9sQ94BPit8fHrtnruLdyL48D7xpf3Az/a6rk3aC/+BLgR+P4lrr8N+AYQ4GbgoSG3u9GP8P1YhhVT96KqHqiqZ8eHpxi952E7GvJ9AfAxRp/L9IvNHG6TDdmL9wLHquppgKp6cpNn3CxD9qKA14wvvxb4ySbOt2mq6kFGf/F4KYeAz9fIKeDqJK+fdrsbHfyLfSzD7kutqarngRc+lmG7GbIXk+5g9BN8O5q6F+NfUfdW1dc3c7AtMOT74jrguiTfSXIqyYFNm25zDdmLjwK3J7kAnADevzmjXXZeak+ATf5oBQ2T5HZgHnjrVs+yFZK8AvgE8O4tHuVysZPR0zq3MPqt78Ekv19V/7WlU22NI8Dnquofk/wxo/f/vLmq/merB3s52OhH+H4sw4ohe0GStwMfBg5W1S83abbNNm0vrgLeDHw7yY8YPUe5sE1fuB3yfXEBWKiqX1XVD4EfMPoBsN0M2Ys7gPsBquq7wKsYfbBaN4N6stpGB9+PZVgxdS+S3AB8mlHst+vztDBlL6rqmaraVVXXVNU1jF7POFhVa/7QqMvYkP8jX2P06J4kuxg9xXNuM4fcJEP24sfA2wCSvIlR8Jc3dcrLwwLwrvFf69wMPFNVP532RRv6lE5t3McyvOwM3It7gVcDXxm/bv3jqjq4ZUNvkIF70cLAvTgJ/HmSs8B/Ax+qqm33W/DAvfgg8Jkkf8voBdx3b8cHiEm+xOiH/K7x6xUfAV4JUFWfYvT6xW3AEvAs8J5Bt7sN90qSdBG+01aSmjD4ktSEwZekJgy+JDVh8CWpCYMvSU0YfElq4n8BzPZcum6w2goAAAAASUVORK5CYII=\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}